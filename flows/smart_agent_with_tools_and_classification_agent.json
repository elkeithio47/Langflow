{
	"id": "e05eb68f-81be-499e-b96f-4bfee78d85f7",
	"data": {
		"nodes": [
			{
				"id": "ToolCallingAgent-IOK4W",
				"type": "genericNode",
				"position": {
					"x": 1360.6137347060893,
					"y": 257.118711211211
				},
				"data": {
					"type": "ToolCallingAgent",
					"node": {
						"template": {
							"_type": "Component",
							"chat_history": {
								"trace_as_metadata": true,
								"list": true,
								"trace_as_input": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "chat_history",
								"value": "",
								"display_name": "Chat History",
								"advanced": true,
								"input_types": [
									"Data"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "DataInput"
							},
							"llm": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "llm",
								"value": "",
								"display_name": "Language Model",
								"advanced": false,
								"input_types": [
									"LanguageModel"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"tools": {
								"trace_as_metadata": true,
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "tools",
								"value": "",
								"display_name": "Tools",
								"advanced": false,
								"input_types": [
									"Tool",
									"BaseTool",
									"StructuredTool"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import DataInput, HandleInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Tool Calling Agent\"\n    description: str = \"Agent that uses tools\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent\"\n\n    inputs = [\n        *LCToolsAgentComponent._base_inputs,\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            msg = \"Prompt must contain 'input' key.\"\n            raise ValueError(msg)\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"handle_parsing_errors": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "handle_parsing_errors",
								"value": true,
								"display_name": "Handle Parse Errors",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"max_iterations": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_iterations",
								"value": 15,
								"display_name": "Max Iterations",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"system_prompt": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "system_prompt",
								"value": "You are a helpful assistant",
								"display_name": "System Prompt",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "System prompt for the agent.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"user_prompt": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "user_prompt",
								"value": "{input}",
								"display_name": "Prompt",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "This prompt must contain 'input' key.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"verbose": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "verbose",
								"value": true,
								"display_name": "Verbose",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Agent that uses tools",
						"icon": "LangChain",
						"base_classes": [
							"AgentExecutor",
							"Message"
						],
						"display_name": "SMART Agent",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"AgentExecutor"
								],
								"selected": "AgentExecutor",
								"name": "agent",
								"display_name": "Agent",
								"method": "build_agent",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"tools"
								]
							},
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "response",
								"display_name": "Response",
								"method": "message_response",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": []
							}
						],
						"field_order": [
							"input_value",
							"handle_parsing_errors",
							"verbose",
							"max_iterations",
							"tools",
							"llm",
							"system_prompt",
							"user_prompt",
							"chat_history"
						],
						"beta": true,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "ToolCallingAgent-IOK4W"
				},
				"selected": false,
				"width": 384,
				"height": 597,
				"positionAbsolute": {
					"x": 1360.6137347060893,
					"y": 257.118711211211
				},
				"dragging": false
			},
			{
				"id": "ChatInput-sHxGF",
				"type": "genericNode",
				"position": {
					"x": -121.27517475233214,
					"y": 5.9604700103406149
				},
				"data": {
					"type": "ChatInput",
					"node": {
						"template": {
							"_type": "Component",
							"files": {
								"trace_as_metadata": true,
								"file_path": "",
								"fileTypes": [
									"txt",
									"md",
									"mdx",
									"csv",
									"json",
									"yaml",
									"yml",
									"xml",
									"html",
									"htm",
									"pdf",
									"docx",
									"py",
									"sh",
									"sql",
									"js",
									"ts",
									"tsx",
									"jpg",
									"jpeg",
									"png",
									"bmp",
									"image"
								],
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "files",
								"value": "",
								"display_name": "Files",
								"advanced": true,
								"dynamic": false,
								"info": "Files to be sent with the message.",
								"title_case": false,
								"type": "file",
								"_input_type": "FileInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.data.utils import IMG_FILE_TYPES, TEXT_FILE_TYPES\nfrom langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, FileInput, MessageTextInput, MultilineInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_USER, MESSAGE_SENDER_USER\n\n\nclass ChatInput(ChatComponent):\n    display_name = \"Chat Input\"\n    description = \"Get chat inputs from the Playground.\"\n    icon = \"ChatInput\"\n    name = \"ChatInput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            value=\"\",\n            info=\"Message to be passed as input.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_USER,\n            info=\"Type of sender.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_USER,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        FileInput(\n            name=\"files\",\n            display_name=\"Files\",\n            file_types=TEXT_FILE_TYPES + IMG_FILE_TYPES,\n            info=\"Files to be sent with the message.\",\n            advanced=True,\n            is_list=True,\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n            files=self.files,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.store_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "I want to know about Mbridge? what is this? what crypto currencies are being used?",
								"display_name": "Text",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Message to be passed as input.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"sender": {
								"trace_as_metadata": true,
								"options": [
									"Machine",
									"User"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sender",
								"value": "User",
								"display_name": "Sender Type",
								"advanced": true,
								"dynamic": false,
								"info": "Type of sender.",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"sender_name": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sender_name",
								"value": "User",
								"display_name": "Sender Name",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Name of the sender.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"session_id": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "session_id",
								"value": "",
								"display_name": "Session ID",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"should_store_message": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "should_store_message",
								"value": true,
								"display_name": "Store Messages",
								"advanced": true,
								"dynamic": false,
								"info": "Store the message in the history.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Get chat inputs from the Playground.",
						"icon": "ChatInput",
						"base_classes": [
							"Message"
						],
						"display_name": "Chat Input",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "message",
								"display_name": "Message",
								"method": "message_response",
								"value": "__UNDEFINED__",
								"cache": true
							}
						],
						"field_order": [
							"input_value",
							"should_store_message",
							"sender",
							"sender_name",
							"session_id",
							"files"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "ChatInput-sHxGF"
				},
				"selected": false,
				"width": 384,
				"height": 291,
				"positionAbsolute": {
					"x": -121.27517475233214,
					"y": 5.9604700103406149
				},
				"dragging": false
			},
			{
				"id": "ChatOutput-CKza3",
				"type": "genericNode",
				"position": {
					"x": 1973.1914130666328,
					"y": 187.15608963779506
				},
				"data": {
					"type": "ChatOutput",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.io.chat import ChatComponent\nfrom langflow.inputs import BoolInput\nfrom langflow.io import DropdownInput, MessageTextInput, Output\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_NAME_AI, MESSAGE_SENDER_USER\n\n\nclass ChatOutput(ChatComponent):\n    display_name = \"Chat Output\"\n    description = \"Display a chat message in the Playground.\"\n    icon = \"ChatOutput\"\n    name = \"ChatOutput\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Message to be passed as output.\",\n        ),\n        BoolInput(\n            name=\"should_store_message\",\n            display_name=\"Store Messages\",\n            info=\"Store the message in the history.\",\n            value=True,\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER],\n            value=MESSAGE_SENDER_AI,\n            advanced=True,\n            info=\"Type of sender.\",\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Name of the sender.\",\n            value=MESSAGE_SENDER_NAME_AI,\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"data_template\",\n            display_name=\"Data Template\",\n            value=\"{text}\",\n            advanced=True,\n            info=\"Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Message\", name=\"message\", method=\"message_response\"),\n    ]\n\n    def message_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n            sender=self.sender,\n            sender_name=self.sender_name,\n            session_id=self.session_id,\n        )\n        if self.session_id and isinstance(message, Message) and self.should_store_message:\n            stored_message = self.store_message(\n                message,\n            )\n            self.message.value = stored_message\n            message = stored_message\n\n        self.status = message\n        return message\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"data_template": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "data_template",
								"value": "{text}",
								"display_name": "Data Template",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Template to convert Data to Text. If left empty, it will be dynamically set to the Data's text key.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Text",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Message to be passed as output.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"sender": {
								"trace_as_metadata": true,
								"options": [
									"Machine",
									"User"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sender",
								"value": "Machine",
								"display_name": "Sender Type",
								"advanced": true,
								"dynamic": false,
								"info": "Type of sender.",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"sender_name": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sender_name",
								"value": "AI",
								"display_name": "Sender Name",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Name of the sender.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"session_id": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "session_id",
								"value": "",
								"display_name": "Session ID",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"should_store_message": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "should_store_message",
								"value": true,
								"display_name": "Store Messages",
								"advanced": true,
								"dynamic": false,
								"info": "Store the message in the history.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Display a chat message in the Playground.",
						"icon": "ChatOutput",
						"base_classes": [
							"Message"
						],
						"display_name": "Chat Output",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "message",
								"display_name": "Message",
								"method": "message_response",
								"value": "__UNDEFINED__",
								"cache": true
							}
						],
						"field_order": [
							"input_value",
							"should_store_message",
							"sender",
							"sender_name",
							"session_id",
							"data_template"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "ChatOutput-CKza3"
				},
				"selected": false,
				"width": 384,
				"height": 291,
				"positionAbsolute": {
					"x": 1973.1914130666328,
					"y": 187.15608963779506
				},
				"dragging": false
			},
			{
				"id": "Prompt-2qjsQ",
				"type": "genericNode",
				"position": {
					"x": 535.1652917130554,
					"y": 149.3741950142362
				},
				"data": {
					"type": "Prompt",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"template": {
								"trace_as_input": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "template",
								"value": "You are an advanced AI agent specialized in performing deep financial research on cryptocurrencies. Your task is to provide comprehensive, insightful analysis using a variety of tools and data sources. Follow these instructions carefully:\n\n1. Review the conversation history:\n<conversation_history>\n{conversation_history}\n</conversation_history>\n\nCarefully analyze this history to understand the context of the current query and any previous information or insights provided.\n\n2. Process the user's query:\n<user_query>\n{input}\n</user_query>\n\n3. Research Methodology:\n   a. Determine which tools are most relevant to answer the query.\n   b. Use the tools in a logical sequence to gather comprehensive data.\n   c. Cross-reference information from multiple sources for accuracy.\n   d. Analyze quantitative and qualitative data to identify trends and patterns.\n   e. Consider short-term, mid-term, and long-term horizons in your analysis.\n   f. Look for interconnections between different trends and weak signals of emerging developments.\n\n4. Available Tools:\n   - Coinmarketcap Real-time Market Data Tool\n   - Google Serper Tool\n   - News Tool\n   - DuckDuckGo Internet Search Tool\n   - Yahoo Finance Crypto Tool\n    - Yahoo Finance Stock Market Tool\n   - Wikipedia Tool\n   - CoinGecko Tool\n   - Classification Analysis Tool\n  -  Sentiment Analysis Tool\n\nUse these tools extensively to gather and analyze data. Always sanitize the data using the Sanitization Tool before processing.\n\n5. Report Generation:\n   a. Synthesize the collected data into coherent insights.\n   b. Structure your report based on the level of detail required:\n      - Summary Report: High-level overview of key insights\n      - Detailed Report: In-depth analysis of each data point\n   c. Include relevant quantitative data, qualitative insights, and trend analysis.\n   d. Provide actionable insights and potential future scenarios.\n\n6. Output Format:\n   Present your final report within <report> tags. Structure it as follows:\n   <report>\n   <summary>\n   [Provide a concise summary of key findings]\n   </summary>\n   \n   <detailed_analysis>\n   [Present your in-depth analysis, broken down into relevant sections]\n   </detailed_analysis>\n   \n   <future_outlook>\n   [Discuss potential future scenarios and their implications]\n   </future_outlook>\n   \n   <actionable_insights>\n   [Provide concrete, actionable recommendations based on your analysis]\n   </actionable_insights>\n   </report>\n\n7. User Satisfaction Check:\n   After presenting your report, ask the user if they are satisfied or if they want you to explore deeper into a specific area of interest. Include this question within <follow_up> tags.\n\nRemember to maintain a professional, analytical tone throughout your response. Your goal is to provide deep, actionable insights that go beyond surface-level analysis. Always strive to connect dots across different data points and identify emerging trends or potential disruptions in the cryptocurrency space.",
								"display_name": "Template",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "prompt",
								"_input_type": "PromptInput"
							},
							"conversation_history": {
								"field_type": "str",
								"required": false,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "",
								"fileTypes": [],
								"file_path": "",
								"name": "conversation_history",
								"display_name": "conversation_history",
								"advanced": false,
								"input_types": [
									"Message",
									"Text"
								],
								"dynamic": false,
								"info": "",
								"load_from_db": false,
								"title_case": false,
								"type": "str"
							},
							"input": {
								"field_type": "str",
								"required": false,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "",
								"fileTypes": [],
								"file_path": "",
								"name": "input",
								"display_name": "input",
								"advanced": false,
								"input_types": [
									"Message",
									"Text"
								],
								"dynamic": false,
								"info": "",
								"load_from_db": false,
								"title_case": false,
								"type": "str"
							}
						},
						"description": "Create a prompt template with dynamic variables.",
						"icon": "prompts",
						"is_input": null,
						"is_output": null,
						"is_composition": null,
						"base_classes": [
							"Message"
						],
						"name": "",
						"display_name": "Prompt",
						"documentation": "",
						"custom_fields": {
							"template": [
								"conversation_history",
								"input"
							]
						},
						"output_types": [],
						"full_path": null,
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "prompt",
								"hidden": null,
								"display_name": "Prompt Message",
								"method": "build_prompt",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": null
							}
						],
						"field_order": [
							"template"
						],
						"beta": false,
						"error": null,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "Prompt-2qjsQ"
				},
				"selected": false,
				"width": 384,
				"height": 480,
				"positionAbsolute": {
					"x": 535.1652917130554,
					"y": 149.3741950142362
				},
				"dragging": false
			},
			{
				"id": "Memory-Qm0Sj",
				"type": "genericNode",
				"position": {
					"x": 39.93018008267154,
					"y": 522.0582104895686
				},
				"data": {
					"type": "Memory",
					"node": {
						"template": {
							"_type": "Component",
							"memory": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "memory",
								"value": "",
								"display_name": "External Memory",
								"advanced": false,
								"input_types": [
									"BaseChatMessageHistory"
								],
								"dynamic": false,
								"info": "Retrieve messages from an external memory. If empty, it will use the Langflow tables.",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langchain.memory import ConversationBufferMemory\n\nfrom langflow.custom import Component\nfrom langflow.field_typing import BaseChatMemory\nfrom langflow.helpers.data import data_to_text\nfrom langflow.inputs import HandleInput\nfrom langflow.io import DropdownInput, IntInput, MessageTextInput, MultilineInput, Output\nfrom langflow.memory import LCBuiltinChatMemory, get_messages\nfrom langflow.schema import Data\nfrom langflow.schema.message import Message\nfrom langflow.utils.constants import MESSAGE_SENDER_AI, MESSAGE_SENDER_USER\n\n\nclass MemoryComponent(Component):\n    display_name = \"Chat Memory\"\n    description = \"Retrieves stored chat messages from Langflow tables or an external memory.\"\n    icon = \"message-square-more\"\n    name = \"Memory\"\n\n    inputs = [\n        HandleInput(\n            name=\"memory\",\n            display_name=\"External Memory\",\n            input_types=[\"BaseChatMessageHistory\"],\n            info=\"Retrieve messages from an external memory. If empty, it will use the Langflow tables.\",\n        ),\n        DropdownInput(\n            name=\"sender\",\n            display_name=\"Sender Type\",\n            options=[MESSAGE_SENDER_AI, MESSAGE_SENDER_USER, \"Machine and User\"],\n            value=\"Machine and User\",\n            info=\"Filter by sender type.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"sender_name\",\n            display_name=\"Sender Name\",\n            info=\"Filter by sender name.\",\n            advanced=True,\n        ),\n        IntInput(\n            name=\"n_messages\",\n            display_name=\"Number of Messages\",\n            value=100,\n            info=\"Number of messages to retrieve.\",\n            advanced=True,\n        ),\n        MessageTextInput(\n            name=\"session_id\",\n            display_name=\"Session ID\",\n            info=\"The session ID of the chat. If empty, the current session ID parameter will be used.\",\n            advanced=True,\n        ),\n        DropdownInput(\n            name=\"order\",\n            display_name=\"Order\",\n            options=[\"Ascending\", \"Descending\"],\n            value=\"Ascending\",\n            info=\"Order of the messages.\",\n            advanced=True,\n        ),\n        MultilineInput(\n            name=\"template\",\n            display_name=\"Template\",\n            info=\"The template to use for formatting the data. \"\n            \"It can contain the keys {text}, {sender} or any other key in the message data.\",\n            value=\"{sender_name}: {text}\",\n            advanced=True,\n        ),\n    ]\n\n    outputs = [\n        Output(display_name=\"Messages (Data)\", name=\"messages\", method=\"retrieve_messages\"),\n        Output(display_name=\"Messages (Text)\", name=\"messages_text\", method=\"retrieve_messages_as_text\"),\n        Output(display_name=\"Memory\", name=\"lc_memory\", method=\"build_lc_memory\"),\n    ]\n\n    def retrieve_messages(self) -> Data:\n        sender = self.sender\n        sender_name = self.sender_name\n        session_id = self.session_id\n        n_messages = self.n_messages\n        order = \"DESC\" if self.order == \"Descending\" else \"ASC\"\n\n        if sender == \"Machine and User\":\n            sender = None\n\n        if self.memory:\n            # override session_id\n            self.memory.session_id = session_id\n\n            stored = self.memory.messages\n            # langchain memories are supposed to return messages in ascending order\n            if order == \"DESC\":\n                stored = stored[::-1]\n            if n_messages:\n                stored = stored[:n_messages]\n            stored = [Message.from_lc_message(m) for m in stored]\n            if sender:\n                expected_type = MESSAGE_SENDER_AI if sender == MESSAGE_SENDER_AI else MESSAGE_SENDER_USER\n                stored = [m for m in stored if m.type == expected_type]\n        else:\n            stored = get_messages(\n                sender=sender,\n                sender_name=sender_name,\n                session_id=session_id,\n                limit=n_messages,\n                order=order,\n            )\n        self.status = stored\n        return stored\n\n    def retrieve_messages_as_text(self) -> Message:\n        stored_text = data_to_text(self.template, self.retrieve_messages())\n        self.status = stored_text\n        return Message(text=stored_text)\n\n    def build_lc_memory(self) -> BaseChatMemory:\n        chat_memory = self.memory or LCBuiltinChatMemory(flow_id=self.flow_id, session_id=self.session_id)\n        return ConversationBufferMemory(chat_memory=chat_memory)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"n_messages": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "n_messages",
								"value": 100,
								"display_name": "Number of Messages",
								"advanced": true,
								"dynamic": false,
								"info": "Number of messages to retrieve.",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"order": {
								"trace_as_metadata": true,
								"options": [
									"Ascending",
									"Descending"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "order",
								"value": "Ascending",
								"display_name": "Order",
								"advanced": true,
								"dynamic": false,
								"info": "Order of the messages.",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"sender": {
								"trace_as_metadata": true,
								"options": [
									"Machine",
									"User",
									"Machine and User"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sender",
								"value": "Machine and User",
								"display_name": "Sender Type",
								"advanced": true,
								"dynamic": false,
								"info": "Filter by sender type.",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"sender_name": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sender_name",
								"value": "",
								"display_name": "Sender Name",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Filter by sender name.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"session_id": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "session_id",
								"value": "",
								"display_name": "Session ID",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The session ID of the chat. If empty, the current session ID parameter will be used.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"template": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "template",
								"value": "{sender_name}: {text}",
								"display_name": "Template",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The template to use for formatting the data. It can contain the keys {text}, {sender} or any other key in the message data.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							}
						},
						"description": "Retrieves stored chat messages from Langflow tables or an external memory.",
						"icon": "message-square-more",
						"base_classes": [
							"BaseChatMemory",
							"Data",
							"Message"
						],
						"display_name": "Chat Memory",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "messages",
								"display_name": "Messages (Data)",
								"method": "retrieve_messages",
								"value": "__UNDEFINED__",
								"cache": true
							},
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "messages_text",
								"display_name": "Messages (Text)",
								"method": "retrieve_messages_as_text",
								"value": "__UNDEFINED__",
								"cache": true
							},
							{
								"types": [
									"BaseChatMemory"
								],
								"selected": "BaseChatMemory",
								"name": "lc_memory",
								"display_name": "Memory",
								"method": "build_lc_memory",
								"value": "__UNDEFINED__",
								"cache": true
							}
						],
						"field_order": [
							"memory",
							"sender",
							"sender_name",
							"n_messages",
							"session_id",
							"order",
							"template"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "Memory-Qm0Sj"
				},
				"selected": false,
				"width": 384,
				"height": 348,
				"positionAbsolute": {
					"x": 39.93018008267154,
					"y": 522.0582104895686
				},
				"dragging": false
			},
			{
				"id": "WikipediaAPI-ioGxI",
				"type": "genericNode",
				"position": {
					"x": -219.901711388825,
					"y": 1520.8921316577219
				},
				"data": {
					"type": "WikipediaAPI",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import cast\n\nfrom langchain_community.tools import WikipediaQueryRun\nfrom langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import BoolInput, IntInput, MessageTextInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass WikipediaAPIComponent(LCToolComponent):\n    display_name = \"Wikipedia API\"\n    description = \"Call Wikipedia API.\"\n    name = \"WikipediaAPI\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        MessageTextInput(name=\"lang\", display_name=\"Language\", value=\"en\"),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n        BoolInput(name=\"load_all_available_meta\", display_name=\"Load all available meta\", value=False, advanced=True),\n        IntInput(\n            name=\"doc_content_chars_max\", display_name=\"Document content characters max\", value=4000, advanced=True\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n        docs = wrapper.load(self.input_value)\n        data = [Data.from_document(doc) for doc in docs]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return cast(Tool, WikipediaQueryRun(api_wrapper=wrapper))\n\n    def _build_wrapper(self) -> WikipediaAPIWrapper:\n        return WikipediaAPIWrapper(\n            top_k_results=self.k,\n            lang=self.lang,\n            load_all_available_meta=self.load_all_available_meta,\n            doc_content_chars_max=self.doc_content_chars_max,\n        )\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"doc_content_chars_max": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "doc_content_chars_max",
								"value": 4000,
								"display_name": "Document content characters max",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"input_value": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"k": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "k",
								"value": 4,
								"display_name": "Number of results",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"lang": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "lang",
								"value": "en",
								"display_name": "Language",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"load_all_available_meta": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "load_all_available_meta",
								"value": false,
								"display_name": "Load all available meta",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Call Wikipedia API.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "Wikipedia API",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"doc_content_chars_max",
									"input_value",
									"k",
									"lang",
									"load_all_available_meta"
								],
								"hidden": true
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"doc_content_chars_max",
									"input_value",
									"k",
									"lang",
									"load_all_available_meta"
								]
							}
						],
						"field_order": [
							"input_value",
							"lang",
							"k",
							"load_all_available_meta",
							"doc_content_chars_max"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "WikipediaAPI-ioGxI"
				},
				"selected": false,
				"width": 384,
				"height": 464,
				"positionAbsolute": {
					"x": -219.901711388825,
					"y": 1520.8921316577219
				},
				"dragging": false
			},
			{
				"id": "CoinMarketCapAPI-TIwe5",
				"type": "genericNode",
				"position": {
					"x": -623.7634416676201,
					"y": 1523.7748887573892
				},
				"data": {
					"type": "CoinMarketCapAPI",
					"node": {
						"template": {
							"_type": "Component",
							"api_key": {
								"load_from_db": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "api_key",
								"value": "",
								"display_name": "CoinMarketCap API Key",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.field_typing import Tool\r\nfrom langflow.inputs import DictInput, IntInput, MultilineInput, SecretStrInput\r\nfrom langflow.schema import Data\r\nimport requests\r\n\r\nclass CoinMarketCapAPIComponent(LCToolComponent):\r\n    display_name: str = \"CoinMarketCap API\"\r\n    description: str = \"Retrieve latest cryptocurrency data from CoinMarketCap.\"\r\n    name = \"CoinMarketCapAPI\"\r\n    documentation: str = \"https://coinmarketcap.com/api/documentation/v1/\"\r\n\r\n    class CoinMarketCapAPIWrapper:\r\n        \"\"\"Wrapper class to call CoinMarketCap API and retrieve cryptocurrency data.\"\"\"\r\n        def __init__(self, api_key: str):\r\n            self.api_key = api_key\r\n            self.url = \"https://pro-api.coinmarketcap.com/v1/cryptocurrency/listings/latest\"\r\n            self.headers = {\r\n                \"Accepts\": \"application/json\",\r\n                \"X-CMC_PRO_API_KEY\": self.api_key,\r\n            }\r\n    \r\n        def get_cryptocurrency_data(self, start: int = 1, limit: int = 10) -> list[dict[str, Any]]:\r\n            parameters = {\"start\": start, \"limit\": limit, \"convert\": \"USD\"}\r\n            response = requests.get(self.url, headers=self.headers, params=parameters)\r\n            data = response.json()\r\n    \r\n            if response.status_code != 200:\r\n                raise Exception(f\"Error {response.status_code}: {data.get('status', {}).get('error_message', 'Unknown error')}\")\r\n    \r\n            return data[\"data\"]\r\n    \r\n    # Define the inputs needed for this component\r\n    inputs = [\r\n        SecretStrInput(name=\"api_key\", display_name=\"CoinMarketCap API Key\", required=True),\r\n        IntInput(name=\"start\", display_name=\"Start\", value=1 , required=True),\r\n        IntInput(name=\"limit\", display_name=\"Limit\", value=10, required=True),\r\n    ]\r\n    \r\n        # Define the schema for the API tool arguments\r\n    class CoinMarketCapSchema(BaseModel):\r\n        start: int = Field(1, description=\"The rank from which to start the listing\")\r\n        limit: int = Field(10, description=\"The number of cryptocurrencies to retrieve\")\r\n    \r\n    \r\n    # Helper function to build the API wrapper\r\n    def _build_wrapper(self):\r\n        return self.CoinMarketCapAPIWrapper(api_key=self.api_key)\r\n\r\n    # Tool builder function\r\n    def build_tool(self) -> Tool:\r\n        wrapper = self._build_wrapper()\r\n\r\n        def get_crypto_data(\r\n            start: int = 1, limit: int = 10\r\n        ) -> list[dict[str, Any]]:\r\n            # Call the wrapper function to get cryptocurrency data\r\n            return wrapper.get_cryptocurrency_data(start=start, limit=limit)\r\n\r\n        # Return the StructuredTool\r\n        tool = StructuredTool.from_function(\r\n            name=\"coinmarketcap_api\",\r\n            description=\"Fetch latest cryptocurrency data from CoinMarketCap API\",\r\n            func=get_crypto_data,\r\n            args_schema=self.CoinMarketCapSchema,\r\n        )\r\n\r\n        self.status = f\"CoinMarketCap API Tool created with API Key.\"\r\n        return tool\r\n\r\n    # Run model function to trigger the API call\r\n    def run_model(self) -> list[Data]:\r\n        tool = self.build_tool()\r\n        results = tool.run(\r\n            {\r\n                \"start\": self.start,\r\n                \"limit\": self.limit,\r\n            }\r\n        )\r\n\r\n        data_list = [Data(data=result, text=f\"Name: {result['name']}, Price: {result['quote']['USD']['price']}\") for result in results]\r\n\r\n        self.status = data_list\r\n        return data_list    \r\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"limit": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "limit",
								"value": 10,
								"display_name": "Limit",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"start": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "start",
								"value": 1,
								"display_name": "Start",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							}
						},
						"description": "Retrieve latest cryptocurrency data from CoinMarketCap.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "CoinMarketCap API",
						"documentation": "https://coinmarketcap.com/api/documentation/v1/",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key",
									"limit",
									"start"
								]
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key",
									"limit",
									"start"
								]
							}
						],
						"field_order": [
							"api_key",
							"start",
							"limit"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "CoinMarketCapAPI-TIwe5"
				},
				"selected": false,
				"width": 384,
				"height": 520,
				"positionAbsolute": {
					"x": -623.7634416676201,
					"y": 1523.7748887573892
				},
				"dragging": false
			},
			{
				"id": "DuckDuckGoSearch-GlscT",
				"type": "genericNode",
				"position": {
					"x": -1021.7438432465718,
					"y": 1525.8547690494755
				},
				"data": {
					"type": "DuckDuckGoSearch",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any\n\nfrom langchain.tools import StructuredTool\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom pydantic import BaseModel, Field\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import IntInput, MessageTextInput\nfrom langflow.schema import Data\n\n\nclass DuckDuckGoSearchComponent(LCToolComponent):\n    display_name: str = \"DuckDuckGo Search\"\n    description: str = \"Perform web searches using the DuckDuckGo search engine with result limiting\"\n    name = \"DuckDuckGoSearch\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon: str = \"DuckDuckGo\"\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n        ),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    class DuckDuckGoSearchSchema(BaseModel):\n        query: str = Field(..., description=\"The search query\")\n        max_results: int = Field(5, description=\"Maximum number of results to return\")\n        max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n    def _build_wrapper(self):\n        return DuckDuckGoSearchRun()\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n\n        def search_func(query: str, max_results: int = 5, max_snippet_length: int = 100) -> list[dict[str, Any]]:\n            full_results = wrapper.run(f\"{query} (site:*)\")\n            result_list = full_results.split(\"\\n\")[:max_results]\n            limited_results = []\n            for result in result_list:\n                limited_result = {\n                    \"snippet\": result[:max_snippet_length],\n                }\n                limited_results.append(limited_result)\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"duckduckgo_search\",\n            description=\"Search for recent results using DuckDuckGo with result limiting\",\n            func=search_func,\n            args_schema=self.DuckDuckGoSearchSchema,\n        )\n        self.status = \"DuckDuckGo Search Tool created\"\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n        results = tool.run(\n            {\n                \"query\": self.input_value,\n                \"max_results\": self.max_results,\n                \"max_snippet_length\": self.max_snippet_length,\n            }\n        )\n        data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n        self.status = data_list\n        return data_list\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "cryptocurrency",
								"display_name": "Search Query",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"max_results": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_results",
								"value": 5,
								"display_name": "Max Results",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"max_snippet_length": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_snippet_length",
								"value": 100,
								"display_name": "Max Snippet Length",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							}
						},
						"description": "Perform web searches using the DuckDuckGo search engine with result limiting",
						"icon": "DuckDuckGo",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "DuckDuckGo Search",
						"documentation": "https://python.langchain.com/docs/integrations/tools/ddg",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"max_results",
									"max_snippet_length"
								],
								"hidden": true
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"max_results",
									"max_snippet_length"
								]
							}
						],
						"field_order": [
							"input_value",
							"max_results",
							"max_snippet_length"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "DuckDuckGoSearch-GlscT"
				},
				"selected": false,
				"width": 384,
				"height": 307,
				"positionAbsolute": {
					"x": -1021.7438432465718,
					"y": 1525.8547690494755
				},
				"dragging": false
			},
			{
				"id": "NewsAPI-fcZCA",
				"type": "genericNode",
				"position": {
					"x": -1423.9157558683515,
					"y": 1522.6992360602627
				},
				"data": {
					"type": "NewsAPI",
					"node": {
						"template": {
							"_type": "Component",
							"api_key": {
								"load_from_db": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "api_key",
								"value": "",
								"display_name": "News API Key",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any, List, Dict\nfrom pydantic import BaseModel, Field\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.inputs import IntInput, MessageTextInput, SecretStrInput\nfrom langflow.schema import Data\nimport requests\n\n\n# Define the component class for News API\nclass NewsAPIComponent(LCToolComponent):\n    display_name: str = \"News API\"\n    description: str = \"Retrieve the latest news articles using the News API.\"\n    name = \"NewsAPI\"\n    documentation: str = \"https://newsapi.org/docs/endpoints/everything\"\n\n    # Define the inputs needed for this component\n    inputs = [\n        SecretStrInput(name=\"api_key\", display_name=\"News API Key\", required=True),\n        MessageTextInput(name=\"query\", display_name=\"Search Query\", required=True),\n        IntInput(name=\"page_size\", display_name=\"Number of Results\", value=10, required=False),\n        MessageTextInput(name=\"language\", display_name=\"Language\", value=\"en\", required=False),\n        MessageTextInput(name=\"sort_by\", display_name=\"Sort By\", value=\"publishedAt\", required=False),\n        MessageTextInput(name=\"from_date\", display_name=\"From Date (YYYY-MM-DD)\", required=False),\n        MessageTextInput(name=\"to_date\", display_name=\"To Date (YYYY-MM-DD)\", required=False),\n        MessageTextInput(name=\"sources\", display_name=\"News Sources\", required=False),\n        MessageTextInput(name=\"domains\", display_name=\"Domains\", required=False),\n    ]\n\n    # Define the schema for the API tool arguments\n    class NewsAPISchema(BaseModel):\n        api_key: str = Field(..., description=\"Your News API Key\")\n        query: str = Field(..., description=\"The search query to look for in articles\")\n        page_size: int = Field(10, description=\"Number of articles to return\")\n        language: str = Field(\"en\", description=\"The language of the articles (default is 'en')\")\n        sort_by: str = Field(\"publishedAt\", description=\"Sort by relevancy, popularity, or published date (default is 'publishedAt')\")\n        from_date: str = Field(None, description=\"Start date for the news articles (YYYY-MM-DD)\")\n        to_date: str = Field(None, description=\"End date for the news articles (YYYY-MM-DD)\")\n        sources: str = Field(None, description=\"Comma-separated list of news sources (e.g., 'bbc-news, techcrunch')\")\n        domains: str = Field(None, description=\"Comma-separated list of domains (e.g., 'wsj.com, bbc.co.uk')\")\n\n    # Define the API Wrapper for News API\n    class NewsAPIWrapper:\n        BASE_URL = \"https://newsapi.org/v2/everything\"\n\n        def __init__(self, api_key: str):\n            self.api_key = api_key\n\n        def get_news(self, query: str, page_size: int = 10, language: str = \"en\", sort_by: str = \"publishedAt\", from_date: str = None, to_date: str = None, sources: str = None, domains: str = None) -> List[Dict[str, Any]]:\n            # Prepare request parameters based on inputs\n            params = {\n                \"q\": query,\n                \"pageSize\": page_size,\n                \"language\": language,\n                \"sortBy\": sort_by,\n                \"from\": from_date,\n                \"to\": to_date,\n                \"sources\": sources,\n                \"domains\": domains,\n                \"apiKey\": \"32e88604cf474c199dea193cccd63e96\"  # self.api_key,  # Use the provided API key dynamically\n            }\n\n            # Remove None values from params\n            params = {k: v for k, v in params.items() if v is not None}\n\n            # Print out the details of the API request\n            print(\"\\n[INFO] - Sending request to News API...\")\n            print(f\"[INFO] - API Endpoint: {self.BASE_URL}\")\n            print(f\"[INFO] - Request Parameters: {params}\")\n\n            response = requests.get(self.BASE_URL, params=params)\n\n            # Handle common errors gracefully\n            if response.status_code == 401:\n                print(\"[ERROR] - Unauthorized request. Check your API key.\")\n                raise Exception(\"Error 401: Unauthorized. Please check your API key.\")\n            elif response.status_code == 429:\n                print(\"[ERROR] - Rate limit exceeded.\")\n                raise Exception(\"Error 429: Too many requests. Rate limit exceeded.\")\n            elif response.status_code != 200:\n                error_message = response.json().get('message', 'Unknown error')\n                print(f\"[ERROR] - Error {response.status_code}: {error_message}\")\n                raise Exception(f\"Error {response.status_code}: {error_message}\")\n\n            print(\"[INFO] - Request successful. Processing response data...\")\n            return response.json().get('articles', [])\n\n    # Build the API wrapper\n    def _build_wrapper(self, api_key: str):\n        print(f\"[INFO] - Building API wrapper with API Key: {api_key[:5]}***\")\n        return self.NewsAPIWrapper(api_key=api_key)\n\n    # Tool builder function\n    def build_tool(self) -> Tool:\n        def get_news(api_key: str, query: str, page_size: int = 10, language: str = \"en\", sort_by: str = \"publishedAt\", from_date: str = None, to_date: str = None, sources: str = None, domains: str = None) -> List[Dict[str, Any]]:\n            wrapper = self._build_wrapper(api_key=api_key)\n            return wrapper.get_news(query=query, page_size=page_size, language=language, sort_by=sort_by, from_date=from_date, to_date=to_date, sources=sources, domains=domains)\n\n        tool = StructuredTool.from_function(\n            name=\"news_api\",\n            description=\"Fetch the latest news articles using the News API\",\n            func=get_news,\n            args_schema=self.NewsAPISchema,\n        )\n\n        print(\"[INFO] - News API Tool created successfully.\")\n        return tool\n\n    # Run model function to trigger the API call\n    def run_model(self, inputs: Dict[str, Any]) -> List[Data]:\n        tool = self.build_tool()\n\n        # Print the inputs received\n        print(\"[INFO] - Running model with the following inputs:\")\n        for key, value in inputs.items():\n            print(f\"  {key}: {value}\")\n\n        # The API key and other inputs are passed dynamically\n        results = tool.run(\n            {\n                \"api_key\": inputs[\"api_key\"],\n                \"query\": inputs[\"query\"],\n                \"page_size\": inputs.get(\"page_size\", 10),\n                \"language\": inputs.get(\"language\", \"en\"),\n                \"sort_by\": inputs.get(\"sort_by\", \"publishedAt\"),\n                \"from_date\": inputs.get(\"from_date\", None),\n                \"to_date\": inputs.get(\"to_date\", None),\n                \"sources\": inputs.get(\"sources\", None),\n                \"domains\": inputs.get(\"domains\", None),\n            }\n        )\n\n        # Format the results for output\n        data_list = [\n            Data(\n                data=result,\n                text=f\"Title: {result.get('title', 'N/A')}, Description: {result.get('description', 'N/A')}, URL: {result.get('url', 'N/A')}\"\n            )\n            for result in results\n        ]\n\n        print(\"[INFO] - Finished processing the News API response.\")\n        \n        # Print out a cURL command for manual testing\n        print(\"\\n[INFO] - cURL Command for manual test:\")\n        curl_command = (\n            f\"curl -X GET 'https://newsapi.org/v2/everything?\"\n            f\"q={inputs['query']}&\"\n            f\"pageSize={inputs.get('page_size', 10)}&\"\n            f\"language={inputs.get('language', 'en')}&\"\n            f\"sortBy={inputs.get('sort_by', 'publishedAt')}&\"\n            f\"from={inputs.get('from_date', '')}&\"\n            f\"to={inputs.get('to_date', '')}&\"\n            f\"apiKey={inputs['api_key']}'\"\n        )\n        print(curl_command)\n\n        self.status = data_list\n        return data_list\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"domains": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "domains",
								"value": "",
								"display_name": "Domains",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"from_date": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "from_date",
								"value": "",
								"display_name": "From Date (YYYY-MM-DD)",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"language": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "language",
								"value": "en",
								"display_name": "Language",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"page_size": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "page_size",
								"value": 10,
								"display_name": "Number of Results",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"query": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "query",
								"value": "cryptocurrency",
								"display_name": "Search Query",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"sort_by": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sort_by",
								"value": "publishedAt",
								"display_name": "Sort By",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"sources": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "sources",
								"value": "",
								"display_name": "News Sources",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"to_date": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "to_date",
								"value": "",
								"display_name": "To Date (YYYY-MM-DD)",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							}
						},
						"description": "Retrieve the latest news articles using the News API.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "News API",
						"documentation": "https://newsapi.org/docs/endpoints/everything",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key"
								],
								"hidden": true
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key"
								]
							}
						],
						"field_order": [
							"api_key",
							"query",
							"page_size",
							"language",
							"sort_by",
							"from_date",
							"to_date",
							"sources",
							"domains"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "NewsAPI-fcZCA"
				},
				"selected": false,
				"width": 384,
				"height": 827,
				"positionAbsolute": {
					"x": -1423.9157558683515,
					"y": 1522.6992360602627
				},
				"dragging": false
			},
			{
				"id": "GoogleSerpAPI-4AeX6",
				"type": "genericNode",
				"position": {
					"x": -1829.8812507747835,
					"y": 1528.9340590628806
				},
				"data": {
					"type": "GoogleSerpAPI",
					"node": {
						"template": {
							"_type": "Component",
							"api_key": {
								"load_from_db": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "api_key",
								"value": "",
								"display_name": "SerpApi API Key",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.field_typing import Tool\r\nfrom langflow.inputs import IntInput, MessageTextInput, SecretStrInput\r\nfrom langflow.schema import Data\r\nimport requests\r\nimport logging\r\n\r\n# Configure logging\r\nlogging.basicConfig(level=logging.DEBUG)\r\n\r\n# Define the component class for SerpApi\r\nclass GoogleSerpAPIComponent(LCToolComponent):\r\n    display_name: str = \"Google Serp API\"\r\n    description: str = \"Retrieve search results using the Google Serp API.\"\r\n    name = \"GoogleSerpAPI\"\r\n    documentation: str = \"https://serpapi.com/docs/\"\r\n\r\n    # Define the inputs needed for this component\r\n    inputs = [\r\n        SecretStrInput(name=\"api_key\", display_name=\"SerpApi API Key\", required=True),\r\n        MessageTextInput(name=\"query\", display_name=\"Search Query\", required=True),\r\n        IntInput(name=\"num_results\", display_name=\"Number of Results\", value=10, required=True),\r\n        MessageTextInput(name=\"gl\", display_name=\"Geographical Location (gl)\", value=\"us\"),\r\n        MessageTextInput(name=\"hl\", display_name=\"Language (hl)\", value=\"en\"),\r\n    ]\r\n\r\n    # Define the schema for the API tool arguments\r\n    class GoogleSerpAPISchema(BaseModel):\r\n        api_key: str = Field(..., description=\"SerpApi API Key\")\r\n        query: str = Field(..., description=\"The search query string\")\r\n        num_results: int = Field(10, description=\"Number of search results to retrieve\")\r\n        gl: str = Field(\"us\", description=\"Geographical location (e.g., 'us' for United States)\")\r\n        hl: str = Field(\"en\", description=\"Language for the search (e.g., 'en' for English)\")\r\n\r\n    # Define the API Wrapper for SerpApi\r\n    class GoogleSerpAPIWrapper:\r\n        def __init__(self, api_key: str):\r\n            self.api_key = api_key\r\n            self.url = \"https://serpapi.com/search\"\r\n    \r\n        def get_search_results(self, query: str, num_results: int = 10, gl: str = \"us\", hl: str = \"en\") -> list[dict[str, Any]]:\r\n            params = {\r\n                \"q\": query,\r\n                \"num\": num_results,\r\n                \"gl\": gl,\r\n                \"hl\": hl,\r\n                \"engine\": \"google\",\r\n                \"api_key\": \"b9db80f260bf0ad145468f5445375fb55797ef18dac6d1a3c8a68ab917e1123b\" #self.api_key\"\"\r\n            }\r\n\r\n            # Print the API key being used\r\n            logging.debug(f\"API Key: {self.api_key}\")\r\n\r\n            # Log the URL and parameters being sent to SerpApi\r\n            logging.debug(f\"Request URL: {self.url}\")\r\n            logging.debug(f\"Request Params: {params}\")\r\n\r\n            response = requests.get(self.url, params=params)\r\n\r\n            # Log the response status and content\r\n            logging.debug(f\"Response Status Code: {response.status_code}\")\r\n            logging.debug(f\"Response Content: {response.text}\")\r\n\r\n            # Check for errors\r\n            if response.status_code == 403:\r\n                raise Exception(\"Error 403: Forbidden. Please check your API key or request quota.\")\r\n            elif response.status_code == 401:\r\n                raise Exception(\"Error 401: Invalid API key. Please verify your API key.\")\r\n            elif response.status_code != 200:\r\n                raise Exception(f\"Error {response.status_code}: {response.json().get('error', 'Unknown error')}\")\r\n\r\n            # Return the organic results from the response\r\n            return response.json().get('organic_results', [])\r\n\r\n    # Build the API wrapper\r\n    def _build_wrapper(self, api_key: str):\r\n        return self.GoogleSerpAPIWrapper(api_key=api_key)\r\n\r\n    # Tool builder function\r\n    def build_tool(self) -> Tool:\r\n        def get_search_results(api_key: str, query: str, num_results: int = 10, gl: str = \"us\", hl: str = \"en\") -> list[dict[str, Any]]:\r\n            wrapper = self._build_wrapper(api_key=api_key)\r\n            return wrapper.get_search_results(query=query, num_results=num_results, gl=gl, hl=hl)\r\n\r\n        tool = StructuredTool.from_function(\r\n            name=\"google_serp_api\",\r\n            description=\"Fetch search results using Google Serp API\",\r\n            func=get_search_results,\r\n            args_schema=self.GoogleSerpAPISchema,\r\n        )\r\n\r\n        self.status = \"Google Serp API Tool created successfully.\"\r\n        return tool\r\n\r\n    # Run model function to trigger the API call\r\n    def run_model(self) -> list[Data]:\r\n        tool = self.build_tool()\r\n        results = tool.run(\r\n            {\r\n                \"api_key\": self.api_key,\r\n                \"query\": self.query,\r\n                \"num_results\": self.num_results,\r\n                \"gl\": self.gl,\r\n                \"hl\": self.hl,\r\n            }\r\n        )\r\n\r\n        # Format the results for output\r\n        data_list = [Data(data=result, text=f\"Title: {result['title']}, Snippet: {result['snippet']}\") for result in results]\r\n\r\n        self.status = data_list\r\n        return data_list\r\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"gl": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "gl",
								"value": "us",
								"display_name": "Geographical Location (gl)",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"hl": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "hl",
								"value": "en",
								"display_name": "Language (hl)",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"num_results": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "num_results",
								"value": 4,
								"display_name": "Number of Results",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput",
								"load_from_db": false
							},
							"query": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "query",
								"value": "cryptocurrency",
								"display_name": "Search Query",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							}
						},
						"description": "Retrieve search results using the Google Serp API.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "Google Serper API",
						"documentation": "https://serpapi.com/docs/",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key",
									"gl",
									"hl",
									"num_results",
									"query"
								]
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key",
									"gl",
									"hl",
									"num_results",
									"query"
								]
							}
						],
						"field_order": [
							"api_key",
							"query",
							"num_results",
							"gl",
							"hl"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "GoogleSerpAPI-4AeX6"
				},
				"selected": false,
				"width": 384,
				"height": 693,
				"positionAbsolute": {
					"x": -1829.8812507747835,
					"y": 1528.9340590628806
				},
				"dragging": false
			},
			{
				"id": "YahooFinanceCrypto-aYcOX",
				"type": "genericNode",
				"position": {
					"x": 194.3197337881403,
					"y": 1521.7919875435699
				},
				"data": {
					"type": "YahooFinanceCrypto",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any\r\n\r\nfrom langchain.tools import StructuredTool\r\nfrom pydantic import BaseModel, Field\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.field_typing import Tool\r\nfrom langflow.inputs import MessageTextInput, SecretStrInput\r\nfrom langflow.schema import Data\r\nimport yfinance as yf\r\n\r\n\r\n# Define the component class for Yahoo Finance Crypto API\r\nclass YahooFinanceCryptoComponent(LCToolComponent):\r\n    display_name: str = \"Yahoo Finance Crypto\"\r\n    description: str = \"Retrieve cryptocurrency and blockchain-related data using Yahoo Finance.\"\r\n    name = \"YahooFinanceCrypto\"\r\n    documentation: str = \"https://www.yahoofinanceapi.com/\"\r\n\r\n    # Define the inputs needed for this component\r\n    inputs = [\r\n        MessageTextInput(name=\"crypto_symbol\", display_name=\"Cryptocurrency Symbol\", required=True),\r\n        MessageTextInput(name=\"metric\", display_name=\"Financial Metric\", required=False, value=\"summary\"),\r\n    ]\r\n\r\n    # Define the schema for the API tool arguments\r\n    class YahooFinanceCryptoSchema(BaseModel):\r\n        crypto_symbol: str = Field(..., description=\"The cryptocurrency symbol (e.g., BTC-USD for Bitcoin).\")\r\n        metric: str = Field(\"summary\", description=\"The financial metric to retrieve (e.g., 'summary', 'price').\")\r\n\r\n    # Define the API Wrapper for Yahoo Finance\r\n    class YahooFinanceCryptoWrapper:\r\n        def __init__(self, crypto_symbol: str, metric: str = \"summary\"):\r\n            self.crypto_symbol = crypto_symbol\r\n            self.metric = metric\r\n            self.ticker = yf.Ticker(crypto_symbol)  # Initialize with the cryptocurrency symbol\r\n\r\n        def get_crypto_data(self) -> dict[str, Any]:\r\n            # Based on the metric, retrieve the corresponding financial data\r\n            if self.metric == \"summary\":\r\n                return self.ticker.info  # Fetch general summary info\r\n            elif self.metric == \"price\":\r\n                return {\"price\": self.ticker.history(period=\"1d\")[\"Close\"].iloc[-1]}\r\n            elif self.metric == \"history\":\r\n                return self.ticker.history(period=\"1mo\")  # Fetch price history\r\n            else:\r\n                raise ValueError(\"Invalid metric. Please choose 'summary', 'price', or 'history'.\")\r\n\r\n    # Build the API wrapper\r\n    def _build_wrapper(self, crypto_symbol: str, metric: str):\r\n        return self.YahooFinanceCryptoWrapper(crypto_symbol=crypto_symbol, metric=metric)\r\n\r\n    # Tool builder function\r\n    def build_tool(self) -> Tool:\r\n        def get_crypto_data(crypto_symbol: str, metric: str = \"summary\") -> dict[str, Any]:\r\n            wrapper = self._build_wrapper(crypto_symbol=crypto_symbol, metric=metric)\r\n            return wrapper.get_crypto_data()\r\n\r\n        tool = StructuredTool.from_function(\r\n            name=\"yahoo_finance_crypto\",\r\n            description=\"Fetch cryptocurrency data using Yahoo Finance.\",\r\n            func=get_crypto_data,\r\n            args_schema=self.YahooFinanceCryptoSchema,\r\n        )\r\n\r\n        self.status = \"Yahoo Finance Crypto Tool created successfully.\"\r\n        return tool\r\n\r\n    # Run model function to trigger the API call\r\n    def run_model(self) -> list[Data]:\r\n        tool = self.build_tool()\r\n        # Retrieve and pass all necessary inputs\r\n        results = tool.run(\r\n            {\r\n                \"crypto_symbol\": self.crypto_symbol,\r\n                \"metric\": self.metric,\r\n            }\r\n        )\r\n\r\n        # Format the results for output\r\n        if self.metric == \"summary\":\r\n            formatted_results = [Data(data=results, text=f\"Summary: {results}\")]\r\n        elif self.metric == \"price\":\r\n            formatted_results = [Data(data=results, text=f\"Latest Price: {results['price']}\")]\r\n        elif self.metric == \"history\":\r\n            formatted_results = [\r\n                Data(data=results, text=f\"Price History: {results[['Close']].to_dict(orient='list')}\")\r\n            ]\r\n        else:\r\n            formatted_results = [Data(data=results, text=\"No valid data found.\")]\r\n\r\n        self.status = formatted_results\r\n        return formatted_results\r\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"crypto_symbol": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "crypto_symbol",
								"value": "BTC",
								"display_name": "Cryptocurrency Symbol",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"metric": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "metric",
								"value": "summary",
								"display_name": "Financial Metric",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							}
						},
						"description": "Retrieve cryptocurrency and blockchain-related data using Yahoo Finance.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "Yahoo Finance Crypto API",
						"documentation": "https://www.yahoofinanceapi.com/",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"crypto_symbol",
									"metric"
								],
								"hidden": true
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"crypto_symbol",
									"metric"
								]
							}
						],
						"field_order": [
							"crypto_symbol",
							"metric"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "YahooFinanceCrypto-aYcOX"
				},
				"selected": false,
				"width": 384,
				"height": 393,
				"positionAbsolute": {
					"x": 194.3197337881403,
					"y": 1521.7919875435699
				},
				"dragging": false
			},
			{
				"id": "TextOutput-WDNg6",
				"type": "genericNode",
				"position": {
					"x": 1968.6611309972209,
					"y": -126.57971974843902
				},
				"data": {
					"type": "TextOutput",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.io.text import TextComponent\nfrom langflow.io import MultilineInput, Output\nfrom langflow.schema.message import Message\n\n\nclass TextOutputComponent(TextComponent):\n    display_name = \"Text Output\"\n    description = \"Display a text output in the Playground.\"\n    icon = \"type\"\n    name = \"TextOutput\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Text\",\n            info=\"Text to be passed as output.\",\n        ),\n    ]\n    outputs = [\n        Output(display_name=\"Text\", name=\"text\", method=\"text_response\"),\n    ]\n\n    def text_response(self) -> Message:\n        message = Message(\n            text=self.input_value,\n        )\n        self.status = self.input_value\n        return message\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Text",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "Text to be passed as output.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							}
						},
						"description": "Display a text output in the Playground.",
						"icon": "type",
						"base_classes": [
							"Message"
						],
						"display_name": "Text Output",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "text",
								"display_name": "Text",
								"method": "text_response",
								"value": "__UNDEFINED__",
								"cache": true
							}
						],
						"field_order": [
							"input_value"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "TextOutput-WDNg6"
				},
				"selected": false,
				"width": 384,
				"height": 291,
				"positionAbsolute": {
					"x": 1968.6611309972209,
					"y": -126.57971974843902
				},
				"dragging": false
			},
			{
				"id": "CoinGeckoAPI-UxBhk",
				"type": "genericNode",
				"position": {
					"x": 187.84577894295195,
					"y": 1027.0260238244724
				},
				"data": {
					"type": "CoinGeckoAPI",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any, Dict\r\nfrom pydantic import BaseModel, Field\r\nfrom langflow.base.langchain_utilities.model import LCToolComponent\r\nfrom langflow.inputs import MessageTextInput\r\nfrom langflow.schema import Data\r\nimport requests\r\n\r\nclass CoinGeckoComponent(LCToolComponent):\r\n    display_name: str = \"CoinGecko API\"\r\n    description: str = \"Retrieve cryptocurrency data using the CoinGecko API.\"\r\n    name = \"CoinGeckoAPI\"\r\n    documentation: str = \"https://www.coingecko.com/en/api\"\r\n\r\n    # Define the inputs needed for this component\r\n    inputs = [\r\n        MessageTextInput(name=\"crypto_id\", display_name=\"Cryptocurrency ID\", required=True),\r\n        MessageTextInput(name=\"currency\", display_name=\"Fiat Currency\", required=False, value=\"usd\"),\r\n        MessageTextInput(name=\"metric\", display_name=\"Metric Type\", required=False, value=\"price\"),\r\n    ]\r\n\r\n    # Define the schema for the API tool arguments\r\n    class CoinGeckoSchema(BaseModel):\r\n        crypto_id: str = Field(..., description=\"The ID of the cryptocurrency (e.g., 'bitcoin', 'ethereum').\")\r\n        currency: str = Field(\"usd\", description=\"The fiat currency to convert the price into (default is 'usd').\")\r\n        metric: str = Field(\"price\", description=\"The type of metric to retrieve (e.g., 'price', 'market_cap').\")\r\n\r\n    # Define the API Wrapper for CoinGecko\r\n    class CoinGeckoAPIWrapper:\r\n        BASE_URL = \"https://api.coingecko.com/api/v3\"\r\n\r\n        def __init__(self, crypto_id: str, currency: str = \"usd\", metric: str = \"price\"):\r\n            self.crypto_id = crypto_id\r\n            self.currency = currency\r\n            self.metric = metric\r\n\r\n        def get_crypto_data(self) -> Dict[str, Any]:\r\n            url = f\"{self.BASE_URL}/simple/price\"\r\n            params = {\r\n                \"ids\": self.crypto_id,\r\n                \"vs_currencies\": self.currency,\r\n                \"include_market_cap\": \"true\" if self.metric == \"market_cap\" else \"false\",\r\n                \"include_24hr_vol\": \"true\" if self.metric == \"volume\" else \"false\",\r\n                \"include_24hr_change\": \"true\" if self.metric == \"price_change\" else \"false\",\r\n            }\r\n\r\n            response = requests.get(url, params=params)\r\n\r\n            if response.status_code != 200:\r\n                raise Exception(f\"Error {response.status_code}: {response.text}\")\r\n\r\n            data = response.json()\r\n\r\n            if self.crypto_id not in data:\r\n                raise ValueError(f\"Cryptocurrency '{self.crypto_id}' not found.\")\r\n\r\n            return data[self.crypto_id]\r\n\r\n    # Build the API wrapper\r\n    def _build_wrapper(self, crypto_id: str, currency: str, metric: str):\r\n        return self.CoinGeckoAPIWrapper(crypto_id=crypto_id, currency=currency, metric=metric)\r\n\r\n    # Tool builder function\r\n    def build_tool(self)->Tool:\r\n        def get_crypto_data(crypto_id: str, currency: str = \"usd\", metric: str = \"price\") -> Dict[str, Any]:\r\n            wrapper = self._build_wrapper(crypto_id=crypto_id, currency=currency, metric=metric)\r\n            return wrapper.get_crypto_data()\r\n\r\n        tool = StructuredTool.from_function(\r\n            name=\"coingecko_api\",\r\n            description=\"Fetch cryptocurrency data using the CoinGecko API.\",\r\n            func=get_crypto_data,\r\n            args_schema=self.CoinGeckoSchema,\r\n        )\r\n\r\n        self.status = \"CoinGecko API Tool created successfully.\"\r\n        return tool\r\n\r\n    # Run model function to trigger the API call\r\n    def run_model(self) -> list[Data]:\r\n        tool = self.build_tool()\r\n\r\n        # Fetch the CoinGecko cryptocurrency data based on user inputs\r\n        results = tool.run(\r\n            {\r\n                \"crypto_id\": self.crypto_id,\r\n                \"currency\": self.currency,\r\n                \"metric\": self.metric,\r\n            }\r\n        )\r\n\r\n        # Format the results for output\r\n        if self.metric == \"price\":\r\n            formatted_result = Data(data=results, text=f\"Price: {results[self.currency]}\")\r\n        elif self.metric == \"market_cap\":\r\n            formatted_result = Data(data=results, text=f\"Market Cap: {results[f'{self.currency}_market_cap']}\")\r\n        elif self.metric == \"volume\":\r\n            formatted_result = Data(data=results, text=f\"24h Volume: {results[f'{self.currency}_24h_vol']}\")\r\n        elif self.metric == \"price_change\":\r\n            formatted_result = Data(data=results, text=f\"24h Price Change: {results[f'{self.currency}_24h_change']}\")\r\n        else:\r\n            formatted_result = Data(data=results, text=\"No valid data found.\")\r\n\r\n        self.status = [formatted_result]\r\n        return [formatted_result]\r\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"crypto_id": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "crypto_id",
								"value": "BTC",
								"display_name": "Cryptocurrency ID",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"currency": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "currency",
								"value": "usd",
								"display_name": "Fiat Currency",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"metric": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "metric",
								"value": "price",
								"display_name": "Metric Type",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							}
						},
						"description": "Retrieve cryptocurrency data using the CoinGecko API.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "CoinGecko API",
						"documentation": "https://www.coingecko.com/en/api",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"crypto_id",
									"currency",
									"metric"
								],
								"hidden": true
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"crypto_id",
									"currency",
									"metric"
								]
							}
						],
						"field_order": [
							"crypto_id",
							"currency",
							"metric"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "CoinGeckoAPI-UxBhk"
				},
				"selected": false,
				"width": 384,
				"height": 480,
				"positionAbsolute": {
					"x": 187.84577894295195,
					"y": 1027.0260238244724
				},
				"dragging": false
			},
			{
				"id": "Prompt-ldALf",
				"type": "genericNode",
				"position": {
					"x": 3506.6529882781439,
					"y": 953.9375235725441
				},
				"data": {
					"type": "Prompt",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"template": {
								"trace_as_input": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "template",
								"value": "You are an expert data classification analyst tasked with detecting text-based classifications within a body of text based content. Your primary task is to analyze the text provided in the input.\n\n<text_input>\n{input}\n</jtext_input>\n\nAnalyze the content provided in the text input above, following these steps:\n\n1. Input Parsing:\n   - Extract and tokenize the content from the text input.\n   - Identify any structured data fields if present.\n\n2. Data Classification:\n   - Classify the data based on sensitivity, type, domain, access control, and jurisdiction.\n   - Match specific patterns in the text to the classification categories (e.g., detecting PII like names, dates, addresses).\n\n3. Risk Detection:\n   - Scan the data for patterns indicating PII, high-risk data (confidential or restricted), or compliance risks (e.g., GDPR-sensitive information).\n   - Identify and flag any sensitive or high-risk data, providing detailed reasons.\n\n4. Topic Modeling:\n   - Apply a topic modeling algorithm (e.g., Latent Dirichlet Allocation) to detect recurring themes.\n   - Group related problem areas and link them to broader contexts.\n\n5. JSON Response Construction:\n   - Synthesize all previous steps into the final output structure.\n   - Fill out key areas such as classificationCategories, riskIndicators, and topicModeling.\n   - Generate namedEntities and suggestedTags based on your analysis.\n\nProvide your output in the exact JSON format specified below:\n\n<output_format>\n\n\\x7B\n  \"classificationAnalysis\": \\x7B\n    \"summary\": \\x7B\n      \"keyPoints\": [\n        // List key points about the data classification\n      ],\n      \"riskIndicators\": [\n        \\x7B\n          \"description\": \"\",\n          \"data\": [\n            \\x7B\n              \"line\": 0,\n              \"content\": \"\",\n              \"type\": \"\",\n              \"reason\": \"\"\n            \\x7D\n          ],\n          \"suggestedActions\": [\n            // List suggested actions\n          ]\n        \\x7D\n      ]\n    \\x7D,\n    \"classificationCategories\": \\x7B\n      \"keyCategories\": \\x7B\n        // Fill in key categories as specified in the task description\n      \\x7D,\n      \"extendedCategories\": \\x7B\n        // Fill in extended categories as specified in the task description\n      \\x7D\n    \\x7D,\n    \"namedEntities\": [\n      // List named entities found in the content\n    ],\n    \"suggestedTags\": [\n      // List suggested tags based on the analysis\n    ],\n    \"topicModeling\": [\n      \\x7B\n        \"topic\": \"\",\n        \"relatedIssues\": [\n          // List related issues\n        ],\n        \"context\": \"\"\n      \\x7D\n    ]\n  \\x7D\n  \\x7D\n\n</output_format>",
								"display_name": "Template",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "prompt",
								"_input_type": "PromptInput"
							},
							"input": {
								"field_type": "str",
								"required": false,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "",
								"fileTypes": [],
								"file_path": "",
								"name": "input",
								"display_name": "input",
								"advanced": false,
								"input_types": [
									"Message",
									"Text"
								],
								"dynamic": false,
								"info": "",
								"load_from_db": false,
								"title_case": false,
								"type": "str"
							}
						},
						"description": "Create a prompt template with dynamic variables.",
						"icon": "prompts",
						"is_input": null,
						"is_output": null,
						"is_composition": null,
						"base_classes": [
							"Message"
						],
						"name": "",
						"display_name": "Prompt",
						"documentation": "",
						"custom_fields": {
							"template": [
								"input"
							]
						},
						"output_types": [],
						"full_path": null,
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "prompt",
								"hidden": null,
								"display_name": "Prompt Message",
								"method": "build_prompt",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": null
							}
						],
						"field_order": [
							"template"
						],
						"beta": false,
						"error": null,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "Prompt-ldALf"
				},
				"selected": false,
				"width": 384,
				"height": 393,
				"dragging": false,
				"positionAbsolute": {
					"x": 3506.6529882781439,
					"y": 953.9375235725441
				}
			},
			{
				"id": "OpenAIModel-MEUqM",
				"type": "genericNode",
				"position": {
					"x": 3502.1737458198388,
					"y": 1347.5062498401326
				},
				"data": {
					"type": "OpenAIModel",
					"node": {
						"template": {
							"_type": "Component",
							"output_parser": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "output_parser",
								"value": "",
								"display_name": "Output Parser",
								"advanced": true,
								"input_types": [
									"OutputParser"
								],
								"dynamic": false,
								"info": "The parser to use to parse the output of the model",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"api_key": {
								"load_from_db": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "api_key",
								"value": "",
								"display_name": "OpenAI API Key",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The OpenAI API Key to use for the OpenAI model.",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key) if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageInput"
							},
							"json_mode": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "json_mode",
								"value": false,
								"display_name": "JSON Mode",
								"advanced": true,
								"dynamic": false,
								"info": "If True, it will output JSON regardless of passing a schema.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"max_tokens": {
								"trace_as_metadata": true,
								"range_spec": {
									"step_type": "float",
									"min": 0,
									"max": 128000,
									"step": 0.1
								},
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_tokens",
								"value": "",
								"display_name": "Max Tokens",
								"advanced": true,
								"dynamic": false,
								"info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"model_kwargs": {
								"trace_as_input": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "model_kwargs",
								"value": {},
								"display_name": "Model Kwargs",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "dict",
								"_input_type": "DictInput"
							},
							"model_name": {
								"trace_as_metadata": true,
								"options": [
									"gpt-4o-mini",
									"gpt-4o",
									"gpt-4-turbo",
									"gpt-4-turbo-preview",
									"gpt-4",
									"gpt-3.5-turbo",
									"gpt-3.5-turbo-0125"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "model_name",
								"value": "gpt-3.5-turbo",
								"display_name": "Model Name",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"openai_api_base": {
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "openai_api_base",
								"value": "",
								"display_name": "OpenAI API Base",
								"advanced": true,
								"dynamic": false,
								"info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
								"title_case": false,
								"type": "str",
								"_input_type": "StrInput"
							},
							"output_schema": {
								"trace_as_input": true,
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "output_schema",
								"value": {},
								"display_name": "Schema",
								"advanced": true,
								"dynamic": false,
								"info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
								"title_case": false,
								"type": "dict",
								"_input_type": "DictInput"
							},
							"seed": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "seed",
								"value": 1,
								"display_name": "Seed",
								"advanced": true,
								"dynamic": false,
								"info": "The seed controls the reproducibility of the job.",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"stream": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "stream",
								"value": false,
								"display_name": "Stream",
								"advanced": true,
								"dynamic": false,
								"info": "Stream the response from the model. Streaming works only in Chat.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"system_message": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "system_message",
								"value": "",
								"display_name": "System Message",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "System message to pass to the model.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"temperature": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "temperature",
								"value": 0.1,
								"display_name": "Temperature",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "float",
								"_input_type": "FloatInput"
							}
						},
						"description": "Generates text using OpenAI LLMs.",
						"icon": "OpenAI",
						"base_classes": [
							"LanguageModel",
							"Message"
						],
						"display_name": "OpenAI",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "text_output",
								"display_name": "Text",
								"method": "text_response",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"stream",
									"system_message"
								],
								"hidden": true
							},
							{
								"types": [
									"LanguageModel"
								],
								"selected": "LanguageModel",
								"name": "model_output",
								"display_name": "Language Model",
								"method": "build_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key",
									"json_mode",
									"max_tokens",
									"model_kwargs",
									"model_name",
									"openai_api_base",
									"output_schema",
									"seed",
									"temperature"
								]
							}
						],
						"field_order": [
							"input_value",
							"system_message",
							"stream",
							"max_tokens",
							"model_kwargs",
							"json_mode",
							"output_schema",
							"model_name",
							"openai_api_base",
							"api_key",
							"temperature",
							"seed",
							"output_parser"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "OpenAIModel-MEUqM"
				},
				"selected": false,
				"width": 384,
				"height": 551,
				"dragging": false,
				"positionAbsolute": {
					"x": 3502.1737458198388,
					"y": 1347.5062498401326
				}
			},
			{
				"id": "AgentAsTool-qe9Bj",
				"type": "genericNode",
				"position": {
					"x": 3991.05887963537,
					"y": 1617.4823770102158
				},
				"data": {
					"type": "AgentAsTool_Classification",
					"node": {
						"template": {
							"_type": "Component",
							"agent": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "agent",
								"value": "",
								"display_name": "Agent",
								"advanced": false,
								"input_types": [
									"AgentExecutor"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.custom import Component\nfrom langflow.inputs import HandleInput\nfrom langchain_core.tools import Tool, tool\nfrom langflow.template import Output\nfrom typing import Any, Dict\nfrom langflow.base.agents.callback import AgentAsyncHandler\n\nclass AgentAsTool(Component):\n    icon = \"arrow-right-to-line\"\n    display_name = \"Agent As Tool Classification\"\n    description = \"Allows to invoke another agent as a tool\"\n    name = \"AgentAsTool_Classification\"\n\n    inputs = [\n        HandleInput(name=\"agent\", display_name=\"Agent\", input_types=[\"AgentExecutor\"], required=True),\n    ]\n\n    outputs = [\n       Output(display_name=\"Tool\", name=\"agent_tool_classification\", method=\"get_tool_agent\"),\n    ]\n\n    def get_tool_agent(\n        self\n    ) -> Tool:     \n                \n        \n\n        @tool()\n        def toolAgent(query: str) -> Dict[str, Any]:\n            \"\"\"\n                This will invoke another agent as a tool and reurn the response form the agent\n            \"\"\"\n            local_agent = self.agent\n            return local_agent.invoke(query, config={\"callbacks\": [AgentAsyncHandler(self.log), *self.get_langchain_callbacks()]})\n\n        return toolAgent # type: ignore",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							}
						},
						"description": "Allows to invoke another agent as a tool",
						"icon": "arrow-right-to-line",
						"base_classes": [
							"Tool"
						],
						"display_name": "Custom Component Classification",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "agent_tool_classification",
								"display_name": "Tool",
								"method": "get_tool_agent",
								"value": "__UNDEFINED__",
								"cache": true
							}
						],
						"field_order": [
							"agent"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "AgentAsTool-qe9Bj"
				},
				"selected": false,
				"width": 384,
				"height": 252,
				"dragging": false,
				"positionAbsolute": {
					"x": 3991.05887963537,
					"y": 1617.4823770102158
				}
			},
			{
				"id": "ToolCallingAgent-c5w9e",
				"type": "genericNode",
				"position": {
					"x": 3985.824373355024,
					"y": 953.5295296134311
				},
				"data": {
					"type": "ToolCallingAgent_Classification",
					"node": {
						"template": {
							"_type": "Component",
							"chat_history": {
								"trace_as_metadata": true,
								"list": true,
								"trace_as_input": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "chat_history",
								"value": "",
								"display_name": "Chat History",
								"advanced": true,
								"input_types": [
									"Data"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "DataInput"
							},
							"llm": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "llm",
								"value": "",
								"display_name": "Language Model",
								"advanced": false,
								"input_types": [
									"LanguageModel"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"tools": {
								"trace_as_metadata": true,
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "tools",
								"value": "",
								"display_name": "Tools",
								"advanced": false,
								"input_types": [
									"Tool",
									"BaseTool",
									"StructuredTool"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import DataInput, HandleInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Classification Analysis Agent\"\n    description: str = \"Expert data classification analyst tasked with detecting text-based classifications \"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent_Classification\"\n\n    inputs = [\n        *LCToolsAgentComponent._base_inputs,\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            msg = \"Prompt must contain 'input' key.\"\n            raise ValueError(msg)\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"handle_parsing_errors": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "handle_parsing_errors",
								"value": true,
								"display_name": "Handle Parse Errors",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"max_iterations": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_iterations",
								"value": 5,
								"display_name": "Max Iterations",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput",
								"load_from_db": false
							},
							"system_prompt": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "system_prompt",
								"value": "You are a helpful assistant",
								"display_name": "System Prompt",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "System prompt for the agent.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"user_prompt": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "user_prompt",
								"value": "{input}",
								"display_name": "Prompt",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "This prompt must contain 'input' key.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"verbose": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "verbose",
								"value": true,
								"display_name": "Verbose",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Expert data classification analyst tasked with detecting text-based classifications ",
						"icon": "LangChain",
						"base_classes": [
							"AgentExecutor",
							"Message"
						],
						"display_name": "Classification Analysis Agent",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"AgentExecutor"
								],
								"selected": "AgentExecutor",
								"name": "agent",
								"display_name": "Agent",
								"method": "build_agent",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"tools"
								]
							},
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "response",
								"display_name": "Response",
								"method": "message_response",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": []
							}
						],
						"field_order": [
							"input_value",
							"handle_parsing_errors",
							"verbose",
							"max_iterations",
							"tools",
							"llm",
							"system_prompt",
							"user_prompt",
							"chat_history"
						],
						"beta": true,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "ToolCallingAgent-c5w9e"
				},
				"selected": false,
				"width": 384,
				"height": 616,
				"positionAbsolute": {
					"x": 3985.824373355024,
					"y": 953.5295296134311
				},
				"dragging": false
			},
			{
				"id": "Prompt-fqS6s",
				"type": "genericNode",
				"position": {
					"x": 3471.0750938138678,
					"y": 2040.80900765902
				},
				"data": {
					"type": "Prompt",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.prompts.api_utils import process_prompt_template\nfrom langflow.custom import Component\nfrom langflow.inputs.inputs import DefaultPromptField\nfrom langflow.io import Output, PromptInput\nfrom langflow.schema.message import Message\nfrom langflow.template.utils import update_template_values\n\n\nclass PromptComponent(Component):\n    display_name: str = \"Prompt\"\n    description: str = \"Create a prompt template with dynamic variables.\"\n    icon = \"prompts\"\n    trace_type = \"prompt\"\n    name = \"Prompt\"\n\n    inputs = [\n        PromptInput(name=\"template\", display_name=\"Template\"),\n    ]\n\n    outputs = [\n        Output(display_name=\"Prompt Message\", name=\"prompt\", method=\"build_prompt\"),\n    ]\n\n    async def build_prompt(\n        self,\n    ) -> Message:\n        prompt = await Message.from_template_and_variables(**self._attributes)\n        self.status = prompt.text\n        return prompt\n\n    def _update_template(self, frontend_node: dict):\n        prompt_template = frontend_node[\"template\"][\"template\"][\"value\"]\n        custom_fields = frontend_node[\"custom_fields\"]\n        frontend_node_template = frontend_node[\"template\"]\n        _ = process_prompt_template(\n            template=prompt_template,\n            name=\"template\",\n            custom_fields=custom_fields,\n            frontend_node_template=frontend_node_template,\n        )\n        return frontend_node\n\n    def post_code_processing(self, new_frontend_node: dict, current_frontend_node: dict):\n        \"\"\"This function is called after the code validation is done.\"\"\"\n        frontend_node = super().post_code_processing(new_frontend_node, current_frontend_node)\n        template = frontend_node[\"template\"][\"template\"][\"value\"]\n        # Kept it duplicated for backwards compatibility\n        _ = process_prompt_template(\n            template=template,\n            name=\"template\",\n            custom_fields=frontend_node[\"custom_fields\"],\n            frontend_node_template=frontend_node[\"template\"],\n        )\n        # Now that template is updated, we need to grab any values that were set in the current_frontend_node\n        # and update the frontend_node with those values\n        update_template_values(new_template=frontend_node, previous_template=current_frontend_node[\"template\"])\n        return frontend_node\n\n    def _get_fallback_input(self, **kwargs):\n        return DefaultPromptField(**kwargs)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"template": {
								"trace_as_input": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "template",
								"value": "You are an expert data sentiment analyst tasked with detecting and analyzing text-based sentiments in a document's content. Your goal is to perform a deep analysis of a single document and provide a detailed report that will contribute to a Trends Datastore for larger dataset insights.\n\nYou will receive a text input with the following structure:\n\n<text_input>\n{input}\n</text_input>\n\nFollow these steps to complete your analysis:\n\n1. Preprocessing:\n   - Clean, tokenize, and normalize the text in the \"content\" field\n   - Remove stop words to improve accuracy\n\n2. Sentiment Detection:\n   - Apply NLP techniques to detect overall sentiment (positive, negative, neutral)\n   - Identify subtle emotional tones (anger, joy, sadness, surprise)\n\n3. Classification of Sentiment Data:\n   - Categorize sentiments into domain-specific categories\n   - Tag data with relevant metadata\n\n4. Identifying Trends and Patterns:\n   - Analyze sentiment trends within the document\n   - Look for emerging patterns or shifts in sentiment\n\n5. Entity and Topic Extraction:\n   - Extract key entities (people, organizations, products)\n   - Identify main topics related to the sentiment\n\n6. Anomaly Detection and Deeper Insights:\n   - Identify outliers or sudden changes in sentiment\n   - Uncover hidden insights by correlating sentiment data with content\n\nAfter completing your analysis, provide your output in the following JSON format:\n\n<output_format>\n\\x7B\n  \"sentiment_analysis\": \\x7B\n    \"overall_sentiment_score\": 0.0,\n    \"sentiment_classification\": \"positive | negative | neutral\",\n    \"sentiment_trends\": [\n      \\x7B\n        \"text_segment\": \"string\",\n        \"sentiment_score\": 0.0,\n        \"sentiment_classification\": \"positive | negative | neutral\",\n        \"start_position\": 0,\n        \"end_position\": 0\n      \\x7D\n    ],\n    \"sentiment_by_section\": \\x7B\n      \"introduction\": \\x7B\n        \"sentiment_score\": 0.0,\n        \"sentiment_classification\": \"positive | negative | neutral\"\n      \\x7D,\n      \"body\": \\x7B\n        \"sentiment_score\": 0.0,\n        \"sentiment_classification\": \"positive | negative | neutral\"\n      \\x7D,\n      \"conclusion\": \\x7B\n        \"sentiment_score\": 0.0,\n        \"sentiment_classification\": \"positive | negative | neutral\"\n      \\x7D\n    \\x7D\n  \\x7D,\n  \"key_entities\": \\x7B\n    \"persons\": [\n      \\x7B\n        \"name\": \"string\",\n        \"sentiment_associated\": 0.0,\n        \"frequency\": 0\n      \\x7D\n    ],\n    \"organizations\": [\n      \\x7B\n        \"name\": \"string\",\n        \"sentiment_associated\": 0.0,\n        \"frequency\": 0\n      \\x7D\n    ],\n    \"locations\": [\n      \\x7B\n        \"name\": \"string\",\n        \"sentiment_associated\": 0.0,\n        \"frequency\": 0\n      \\x7D\n    ],\n    \"topics\": [\n      \\x7B\n        \"topic\": \"string\",\n        \"sentiment_associated\": 0.0,\n        \"frequency\": 0\n      \\x7D\n    ]\n  \\x7D,\n  \"deep_insights\": \\x7B\n    \"key_findings\": [\n      \\x7B\n        \"finding\": \"string\",\n        \"supporting_evidence\": \"string\",\n        \"relevance_score\": 0.0\n      \\x7D\n    ],\n    \"emerging_patterns\": [\n      \\x7B\n        \"pattern\": \"string\",\n        \"correlation_strength\": 0.0,\n        \"dimension_affected\": \"string\"\n      \\x7D\n    ]\n  \\x7D\n\\x7D\n</output_format>\n\nFill out each section of the output JSON as follows:\n\n1. sentiment_analysis: Provide overall scores, classifications, and detailed breakdowns\n2. key_entities: List and analyze important persons, organizations, locations, and topics\n3. deep_insights: Highlight key findings and emerging patterns\n\nEnsure that all numerical scores are between 0 and 1, where applicable. Provide detailed justifications for your classifications and insights. Maintain consistency and accuracy throughout your analysis, and ensure that your output adheres strictly to the provided JSON structure.",
								"display_name": "Template",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "prompt",
								"_input_type": "PromptInput"
							},
							"input": {
								"field_type": "str",
								"required": false,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "",
								"fileTypes": [],
								"file_path": "",
								"name": "input",
								"display_name": "input",
								"advanced": false,
								"input_types": [
									"Message",
									"Text"
								],
								"dynamic": false,
								"info": "",
								"load_from_db": false,
								"title_case": false,
								"type": "str"
							}
						},
						"description": "Create a prompt template with dynamic variables.",
						"icon": "prompts",
						"is_input": null,
						"is_output": null,
						"is_composition": null,
						"base_classes": [
							"Message"
						],
						"name": "",
						"display_name": "Prompt",
						"documentation": "",
						"custom_fields": {
							"template": [
								"input"
							]
						},
						"output_types": [],
						"full_path": null,
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "prompt",
								"hidden": null,
								"display_name": "Prompt Message",
								"method": "build_prompt",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": null
							}
						],
						"field_order": [
							"template"
						],
						"beta": false,
						"error": null,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "Prompt-fqS6s"
				},
				"selected": false,
				"width": 384,
				"height": 393,
				"dragging": false,
				"positionAbsolute": {
					"x": 3471.0750938138678,
					"y": 2040.80900765902
				}
			},
			{
				"id": "OpenAIModel-EaIce",
				"type": "genericNode",
				"position": {
					"x": 3474.020297867273,
					"y": 2462.219408345521
				},
				"data": {
					"type": "OpenAIModel",
					"node": {
						"template": {
							"_type": "Component",
							"output_parser": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "output_parser",
								"value": "",
								"display_name": "Output Parser",
								"advanced": true,
								"input_types": [
									"OutputParser"
								],
								"dynamic": false,
								"info": "The parser to use to parse the output of the model",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"api_key": {
								"load_from_db": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "api_key",
								"value": "",
								"display_name": "OpenAI API Key",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The OpenAI API Key to use for the OpenAI model.",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "import operator\nfrom functools import reduce\n\nfrom langchain_openai import ChatOpenAI\nfrom pydantic.v1 import SecretStr\n\nfrom langflow.base.models.model import LCModelComponent\nfrom langflow.base.models.openai_constants import OPENAI_MODEL_NAMES\nfrom langflow.field_typing import LanguageModel\nfrom langflow.field_typing.range_spec import RangeSpec\nfrom langflow.inputs import BoolInput, DictInput, DropdownInput, FloatInput, IntInput, SecretStrInput, StrInput\nfrom langflow.inputs.inputs import HandleInput\n\n\nclass OpenAIModelComponent(LCModelComponent):\n    display_name = \"OpenAI\"\n    description = \"Generates text using OpenAI LLMs.\"\n    icon = \"OpenAI\"\n    name = \"OpenAIModel\"\n\n    inputs = [\n        *LCModelComponent._base_inputs,\n        IntInput(\n            name=\"max_tokens\",\n            display_name=\"Max Tokens\",\n            advanced=True,\n            info=\"The maximum number of tokens to generate. Set to 0 for unlimited tokens.\",\n            range_spec=RangeSpec(min=0, max=128000),\n        ),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True),\n        BoolInput(\n            name=\"json_mode\",\n            display_name=\"JSON Mode\",\n            advanced=True,\n            info=\"If True, it will output JSON regardless of passing a schema.\",\n        ),\n        DictInput(\n            name=\"output_schema\",\n            is_list=True,\n            display_name=\"Schema\",\n            advanced=True,\n            info=\"The schema for the Output of the model. \"\n            \"You must pass the word JSON in the prompt. \"\n            \"If left blank, JSON mode will be disabled. [DEPRECATED]\",\n        ),\n        DropdownInput(\n            name=\"model_name\",\n            display_name=\"Model Name\",\n            advanced=False,\n            options=OPENAI_MODEL_NAMES,\n            value=OPENAI_MODEL_NAMES[0],\n        ),\n        StrInput(\n            name=\"openai_api_base\",\n            display_name=\"OpenAI API Base\",\n            advanced=True,\n            info=\"The base URL of the OpenAI API. \"\n            \"Defaults to https://api.openai.com/v1. \"\n            \"You can change this to use other APIs like JinaChat, LocalAI and Prem.\",\n        ),\n        SecretStrInput(\n            name=\"api_key\",\n            display_name=\"OpenAI API Key\",\n            info=\"The OpenAI API Key to use for the OpenAI model.\",\n            advanced=False,\n            value=\"OPENAI_API_KEY\",\n        ),\n        FloatInput(name=\"temperature\", display_name=\"Temperature\", value=0.1),\n        IntInput(\n            name=\"seed\",\n            display_name=\"Seed\",\n            info=\"The seed controls the reproducibility of the job.\",\n            advanced=True,\n            value=1,\n        ),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        # self.output_schema is a list of dictionaries\n        # let's convert it to a dictionary\n        output_schema_dict: dict[str, str] = reduce(operator.ior, self.output_schema or {}, {})\n        openai_api_key = self.api_key\n        temperature = self.temperature\n        model_name: str = self.model_name\n        max_tokens = self.max_tokens\n        model_kwargs = self.model_kwargs or {}\n        openai_api_base = self.openai_api_base or \"https://api.openai.com/v1\"\n        json_mode = bool(output_schema_dict) or self.json_mode\n        seed = self.seed\n\n        api_key = SecretStr(openai_api_key) if openai_api_key else None\n        output = ChatOpenAI(\n            max_tokens=max_tokens or None,\n            model_kwargs=model_kwargs,\n            model=model_name,\n            base_url=openai_api_base,\n            api_key=api_key,\n            temperature=temperature if temperature is not None else 0.1,\n            seed=seed,\n        )\n        if json_mode:\n            if output_schema_dict:\n                output = output.with_structured_output(schema=output_schema_dict, method=\"json_mode\")\n            else:\n                output = output.bind(response_format={\"type\": \"json_object\"})\n\n        return output\n\n    def _get_exception_message(self, e: Exception):\n        \"\"\"Get a message from an OpenAI exception.\n\n        Args:\n            e (Exception): The exception to get the message from.\n\n        Returns:\n            str: The message from the exception.\n        \"\"\"\n        try:\n            from openai import BadRequestError\n        except ImportError:\n            return None\n        if isinstance(e, BadRequestError):\n            message = e.body.get(\"message\")\n            if message:\n                return message\n        return None\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageInput"
							},
							"json_mode": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "json_mode",
								"value": false,
								"display_name": "JSON Mode",
								"advanced": true,
								"dynamic": false,
								"info": "If True, it will output JSON regardless of passing a schema.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"max_tokens": {
								"trace_as_metadata": true,
								"range_spec": {
									"step_type": "float",
									"min": 0,
									"max": 128000,
									"step": 0.1
								},
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_tokens",
								"value": "",
								"display_name": "Max Tokens",
								"advanced": true,
								"dynamic": false,
								"info": "The maximum number of tokens to generate. Set to 0 for unlimited tokens.",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"model_kwargs": {
								"trace_as_input": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "model_kwargs",
								"value": {},
								"display_name": "Model Kwargs",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "dict",
								"_input_type": "DictInput"
							},
							"model_name": {
								"trace_as_metadata": true,
								"options": [
									"gpt-4o-mini",
									"gpt-4o",
									"gpt-4-turbo",
									"gpt-4-turbo-preview",
									"gpt-4",
									"gpt-3.5-turbo",
									"gpt-3.5-turbo-0125"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "model_name",
								"value": "gpt-3.5-turbo",
								"display_name": "Model Name",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"openai_api_base": {
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "openai_api_base",
								"value": "",
								"display_name": "OpenAI API Base",
								"advanced": true,
								"dynamic": false,
								"info": "The base URL of the OpenAI API. Defaults to https://api.openai.com/v1. You can change this to use other APIs like JinaChat, LocalAI and Prem.",
								"title_case": false,
								"type": "str",
								"_input_type": "StrInput"
							},
							"output_schema": {
								"trace_as_input": true,
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "output_schema",
								"value": {},
								"display_name": "Schema",
								"advanced": true,
								"dynamic": false,
								"info": "The schema for the Output of the model. You must pass the word JSON in the prompt. If left blank, JSON mode will be disabled. [DEPRECATED]",
								"title_case": false,
								"type": "dict",
								"_input_type": "DictInput"
							},
							"seed": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "seed",
								"value": 1,
								"display_name": "Seed",
								"advanced": true,
								"dynamic": false,
								"info": "The seed controls the reproducibility of the job.",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"stream": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "stream",
								"value": false,
								"display_name": "Stream",
								"advanced": true,
								"dynamic": false,
								"info": "Stream the response from the model. Streaming works only in Chat.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"system_message": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "system_message",
								"value": "",
								"display_name": "System Message",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "System message to pass to the model.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"temperature": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "temperature",
								"value": 0.1,
								"display_name": "Temperature",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "float",
								"_input_type": "FloatInput"
							}
						},
						"description": "Generates text using OpenAI LLMs.",
						"icon": "OpenAI",
						"base_classes": [
							"LanguageModel",
							"Message"
						],
						"display_name": "OpenAI",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "text_output",
								"display_name": "Text",
								"method": "text_response",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"stream",
									"system_message"
								],
								"hidden": true
							},
							{
								"types": [
									"LanguageModel"
								],
								"selected": "LanguageModel",
								"name": "model_output",
								"display_name": "Language Model",
								"method": "build_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"api_key",
									"json_mode",
									"max_tokens",
									"model_kwargs",
									"model_name",
									"openai_api_base",
									"output_schema",
									"seed",
									"temperature"
								]
							}
						],
						"field_order": [
							"input_value",
							"system_message",
							"stream",
							"max_tokens",
							"model_kwargs",
							"json_mode",
							"output_schema",
							"model_name",
							"openai_api_base",
							"api_key",
							"temperature",
							"seed",
							"output_parser"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "OpenAIModel-EaIce"
				},
				"selected": false,
				"width": 384,
				"height": 551,
				"dragging": false,
				"positionAbsolute": {
					"x": 3474.020297867273,
					"y": 2462.219408345521
				}
			},
			{
				"id": "AgentAsTool-q4NJV",
				"type": "genericNode",
				"position": {
					"x": 4010.596033846999,
					"y": 2738.8473021665788
				},
				"data": {
					"type": "AgentAsTool_Sentiment",
					"node": {
						"template": {
							"_type": "Component",
							"agent": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "agent",
								"value": "",
								"display_name": "Agent",
								"advanced": false,
								"input_types": [
									"AgentExecutor"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.custom import Component\nfrom langflow.inputs import HandleInput\nfrom langchain_core.tools import Tool, tool\nfrom langflow.template import Output\nfrom typing import Any, Dict\nfrom langflow.base.agents.callback import AgentAsyncHandler\n\nclass AgentAsTool(Component):\n    icon = \"arrow-right-to-line\"\n    display_name = \"Agent As Tool\"\n    description = \"Allows to invoke another agent as a tool\"\n    name = \"AgentAsTool_Sentiment\"\n\n    inputs = [\n        HandleInput(name=\"agent\", display_name=\"Agent\", input_types=[\"AgentExecutor\"], required=True),\n    ]\n\n    outputs = [\n       Output(display_name=\"Tool\", name=\"agent_tool_sentiment\", method=\"get_tool_agent\"),\n    ]\n\n    def get_tool_agent(\n        self\n    ) -> Tool:     \n                \n        \n\n        @tool()\n        def toolAgent(query: str) -> Dict[str, Any]:\n            \"\"\"\n                This will invoke another agent as a tool and reurn the response form the agent\n            \"\"\"\n            local_agent = self.agent\n            return local_agent.invoke(query, config={\"callbacks\": [AgentAsyncHandler(self.log), *self.get_langchain_callbacks()]})\n\n        return toolAgent # type: ignore",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							}
						},
						"description": "Allows to invoke another agent as a tool",
						"icon": "arrow-right-to-line",
						"base_classes": [
							"Tool"
						],
						"display_name": "Custom Component Sentiment",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "agent_tool_sentiment",
								"display_name": "Tool",
								"method": "get_tool_agent",
								"value": "__UNDEFINED__",
								"cache": true
							}
						],
						"field_order": [
							"agent"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "AgentAsTool-q4NJV"
				},
				"selected": false,
				"width": 384,
				"height": 252,
				"dragging": false,
				"positionAbsolute": {
					"x": 4010.596033846999,
					"y": 2738.8473021665788
				}
			},
			{
				"id": "ToolCallingAgent-b1Kk9",
				"type": "genericNode",
				"position": {
					"x": 4013.00320234765,
					"y": 2042.9836585996375
				},
				"data": {
					"type": "ToolCallingAgent_Sentiment",
					"node": {
						"template": {
							"_type": "Component",
							"chat_history": {
								"trace_as_metadata": true,
								"list": true,
								"trace_as_input": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "chat_history",
								"value": "",
								"display_name": "Chat History",
								"advanced": true,
								"input_types": [
									"Data"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "DataInput"
							},
							"llm": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "llm",
								"value": "",
								"display_name": "Language Model",
								"advanced": false,
								"input_types": [
									"LanguageModel"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"tools": {
								"trace_as_metadata": true,
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "tools",
								"value": "",
								"display_name": "Tools",
								"advanced": false,
								"input_types": [
									"Tool",
									"BaseTool",
									"StructuredTool"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langchain.agents import create_tool_calling_agent\nfrom langchain_core.prompts import ChatPromptTemplate, HumanMessagePromptTemplate, PromptTemplate\n\nfrom langflow.base.agents.agent import LCToolsAgentComponent\nfrom langflow.inputs import MultilineInput\nfrom langflow.inputs.inputs import DataInput, HandleInput\nfrom langflow.schema import Data\n\n\nclass ToolCallingAgentComponent(LCToolsAgentComponent):\n    display_name: str = \"Sentiment Analysis Agent\"\n    description: str = \"Expert data sentiment analyst tasked with detecting and analyzing text-based sentiments in a document's content\"\n    icon = \"LangChain\"\n    beta = True\n    name = \"ToolCallingAgent_Sentiment\"\n\n    inputs = [\n        *LCToolsAgentComponent._base_inputs,\n        HandleInput(name=\"llm\", display_name=\"Language Model\", input_types=[\"LanguageModel\"], required=True),\n        MultilineInput(\n            name=\"system_prompt\",\n            display_name=\"System Prompt\",\n            info=\"System prompt for the agent.\",\n            value=\"You are a helpful assistant\",\n        ),\n        MultilineInput(\n            name=\"user_prompt\", display_name=\"Prompt\", info=\"This prompt must contain 'input' key.\", value=\"{input}\"\n        ),\n        DataInput(name=\"chat_history\", display_name=\"Chat History\", is_list=True, advanced=True),\n    ]\n\n    def get_chat_history_data(self) -> list[Data] | None:\n        return self.chat_history\n\n    def create_agent_runnable(self):\n        if \"input\" not in self.user_prompt:\n            msg = \"Prompt must contain 'input' key.\"\n            raise ValueError(msg)\n        messages = [\n            (\"system\", self.system_prompt),\n            (\"placeholder\", \"{chat_history}\"),\n            HumanMessagePromptTemplate(prompt=PromptTemplate(input_variables=[\"input\"], template=self.user_prompt)),\n            (\"placeholder\", \"{agent_scratchpad}\"),\n        ]\n        prompt = ChatPromptTemplate.from_messages(messages)\n        return create_tool_calling_agent(self.llm, self.tools, prompt)\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"handle_parsing_errors": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "handle_parsing_errors",
								"value": true,
								"display_name": "Handle Parse Errors",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"max_iterations": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_iterations",
								"value": 5,
								"display_name": "Max Iterations",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput",
								"load_from_db": false
							},
							"system_prompt": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "system_prompt",
								"value": "You are a helpful assistant",
								"display_name": "System Prompt",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "System prompt for the agent.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"user_prompt": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "user_prompt",
								"value": "{input}",
								"display_name": "Prompt",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "This prompt must contain 'input' key.",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"verbose": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "verbose",
								"value": true,
								"display_name": "Verbose",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Expert data sentiment analyst tasked with detecting and analyzing text-based sentiments in a document's content",
						"icon": "LangChain",
						"base_classes": [
							"AgentExecutor",
							"Message"
						],
						"display_name": "Sentiment Analysis Agent",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"AgentExecutor"
								],
								"selected": "AgentExecutor",
								"name": "agent",
								"display_name": "Agent",
								"method": "build_agent",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"tools"
								]
							},
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "response",
								"display_name": "Response",
								"method": "message_response",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": []
							}
						],
						"field_order": [
							"input_value",
							"handle_parsing_errors",
							"verbose",
							"max_iterations",
							"tools",
							"llm",
							"system_prompt",
							"user_prompt",
							"chat_history"
						],
						"beta": true,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "ToolCallingAgent-b1Kk9"
				},
				"selected": false,
				"width": 384,
				"height": 632,
				"dragging": false,
				"positionAbsolute": {
					"x": 4013.00320234765,
					"y": 2042.9836585996375
				}
			},
			{
				"id": "YahooFinanceTool-DYxhl",
				"type": "genericNode",
				"position": {
					"x": -227.70967733774087,
					"y": 1029.7333787347052
				},
				"data": {
					"type": "YahooFinanceTool",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "import ast\nimport pprint\n\nimport yfinance as yf\nfrom langchain.tools import StructuredTool\nfrom loguru import logger\nfrom pydantic import BaseModel, Field\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import DropdownInput, IntInput, MessageTextInput\nfrom langflow.schema import Data\n\n\nclass YfinanceToolComponent(LCToolComponent):\n    display_name = \"Yahoo Finance Tool\"\n    description = \"Access financial data and market information using Yahoo Finance.\"\n    icon = \"trending-up\"\n    name = \"YahooFinanceTool\"\n\n    inputs = [\n        MessageTextInput(\n            name=\"symbol\",\n            display_name=\"Stock Symbol\",\n            info=\"The stock symbol to retrieve data for (e.g., AAPL, GOOG).\",\n            required=True,\n        ),\n        DropdownInput(\n            name=\"method\",\n            display_name=\"Data Method\",\n            info=\"The type of data to retrieve.\",\n            options=[\n                \"get_actions\",\n                \"get_analysis\",\n                \"get_balance_sheet\",\n                \"get_calendar\",\n                \"get_cashflow\",\n                \"get_info\",\n                \"get_institutional_holders\",\n                \"get_news\",\n                \"get_recommendations\",\n                \"get_sustainability\",\n            ],\n            value=\"get_news\",\n        ),\n        IntInput(\n            name=\"num_news\",\n            display_name=\"Number of News\",\n            info=\"The number of news articles to retrieve (only applicable for get_news).\",\n            value=5,\n        ),\n    ]\n\n    class YahooFinanceSchema(BaseModel):\n        symbol: str = Field(..., description=\"The stock symbol to retrieve data for.\")\n        method: str = Field(\"get_info\", description=\"The type of data to retrieve.\")\n        num_news: int | None = Field(5, description=\"The number of news articles to retrieve.\")\n\n    def run_model(self) -> list[Data]:\n        return self._yahoo_finance_tool(\n            self.symbol,\n            self.method,\n            self.num_news,\n        )\n\n    def build_tool(self) -> Tool:\n        return StructuredTool.from_function(\n            name=\"yahoo_finance\",\n            description=\"Access financial data and market information from Yahoo Finance.\",\n            func=self._yahoo_finance_tool,\n            args_schema=self.YahooFinanceSchema,\n        )\n\n    def _yahoo_finance_tool(\n        self,\n        symbol: str,\n        method: str,\n        num_news: int | None = 5,\n    ) -> list[Data]:\n        ticker = yf.Ticker(symbol)\n\n        try:\n            if method == \"get_info\":\n                result = ticker.info\n            elif method == \"get_news\":\n                result = ticker.news[:num_news]\n            else:\n                result = getattr(ticker, method)()\n\n            result = pprint.pformat(result)\n\n            if method == \"get_news\":\n                data_list = [Data(data=article) for article in ast.literal_eval(result)]\n            else:\n                data_list = [Data(data={\"result\": result})]\n\n        except Exception as e:  # noqa: BLE001\n            error_message = f\"Error retrieving data: {e}\"\n            logger.opt(exception=True).debug(error_message)\n            self.status = error_message\n            return [Data(data={\"error\": error_message})]\n\n        return data_list\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"method": {
								"trace_as_metadata": true,
								"options": [
									"get_actions",
									"get_analysis",
									"get_balance_sheet",
									"get_calendar",
									"get_cashflow",
									"get_info",
									"get_institutional_holders",
									"get_news",
									"get_recommendations",
									"get_sustainability"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "method",
								"value": "get_news",
								"display_name": "Data Method",
								"advanced": false,
								"dynamic": false,
								"info": "The type of data to retrieve.",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"num_news": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "num_news",
								"value": 5,
								"display_name": "Number of News",
								"advanced": false,
								"dynamic": false,
								"info": "The number of news articles to retrieve (only applicable for get_news).",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"symbol": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "symbol",
								"value": "TSLA",
								"display_name": "Stock Symbol",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "The stock symbol to retrieve data for (e.g., AAPL, GOOG).",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							}
						},
						"description": "Access financial data and market information using Yahoo Finance.",
						"icon": "trending-up",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "Yahoo Finance Stock Market API",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"method",
									"num_news",
									"symbol"
								],
								"hidden": true
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"method",
									"num_news",
									"symbol"
								]
							}
						],
						"field_order": [
							"symbol",
							"method",
							"num_news"
						],
						"beta": false,
						"edited": false,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "YahooFinanceTool-DYxhl"
				},
				"selected": false,
				"width": 384,
				"height": 480,
				"dragging": false,
				"positionAbsolute": {
					"x": -227.70967733774087,
					"y": 1029.7333787347052
				}
			},
			{
				"id": "WikipediaAPI1-SGBxx",
				"type": "genericNode",
				"position": {
					"x": 4547.520220843912,
					"y": 903.1018471185616
				},
				"data": {
					"type": "WikipediaAPI1",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import cast\n\nfrom langchain_community.tools import WikipediaQueryRun\nfrom langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import BoolInput, IntInput, MessageTextInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass WikipediaAPIComponent(LCToolComponent):\n    display_name = \"Wikipedia API\"\n    description = \"Call Wikipedia API.\"\n    name = \"WikipediaAPI1\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        MessageTextInput(name=\"lang\", display_name=\"Language\", value=\"en\"),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n        BoolInput(name=\"load_all_available_meta\", display_name=\"Load all available meta\", value=False, advanced=True),\n        IntInput(\n            name=\"doc_content_chars_max\", display_name=\"Document content characters max\", value=4000, advanced=True\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n        docs = wrapper.load(self.input_value)\n        data = [Data.from_document(doc) for doc in docs]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return cast(Tool, WikipediaQueryRun(api_wrapper=wrapper))\n\n    def _build_wrapper(self) -> WikipediaAPIWrapper:\n        return WikipediaAPIWrapper(\n            top_k_results=self.k,\n            lang=self.lang,\n            load_all_available_meta=self.load_all_available_meta,\n            doc_content_chars_max=self.doc_content_chars_max,\n        )\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"doc_content_chars_max": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "doc_content_chars_max",
								"value": 4000,
								"display_name": "Document content characters max",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"input_value": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"k": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "k",
								"value": 4,
								"display_name": "Number of results",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"lang": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "lang",
								"value": "en",
								"display_name": "Language",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"load_all_available_meta": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "load_all_available_meta",
								"value": false,
								"display_name": "Load all available meta",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Call Wikipedia API.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "Wikipedia API 1",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"doc_content_chars_max",
									"input_value",
									"k",
									"lang",
									"load_all_available_meta"
								]
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"doc_content_chars_max",
									"input_value",
									"k",
									"lang",
									"load_all_available_meta"
								]
							}
						],
						"field_order": [
							"input_value",
							"lang",
							"k",
							"load_all_available_meta",
							"doc_content_chars_max"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "WikipediaAPI1-SGBxx"
				},
				"selected": false,
				"width": 384,
				"height": 504,
				"positionAbsolute": {
					"x": 4547.520220843912,
					"y": 903.1018471185616
				},
				"dragging": false
			},
			{
				"id": "DuckDuckGoSearch-nu1XV",
				"type": "genericNode",
				"position": {
					"x": 4541.084903257265,
					"y": 1464.2859834348258
				},
				"data": {
					"type": "DuckDuckGoSearch",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any\n\nfrom langchain.tools import StructuredTool\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom pydantic import BaseModel, Field\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import IntInput, MessageTextInput\nfrom langflow.schema import Data\n\n\nclass DuckDuckGoSearchComponent(LCToolComponent):\n    display_name: str = \"DuckDuckGo Search\"\n    description: str = \"Perform web searches using the DuckDuckGo search engine with result limiting\"\n    name = \"DuckDuckGoSearch\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon: str = \"DuckDuckGo1\"\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n        ),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    class DuckDuckGoSearchSchema(BaseModel):\n        query: str = Field(..., description=\"The search query\")\n        max_results: int = Field(5, description=\"Maximum number of results to return\")\n        max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n    def _build_wrapper(self):\n        return DuckDuckGoSearchRun()\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n\n        def search_func(query: str, max_results: int = 5, max_snippet_length: int = 100) -> list[dict[str, Any]]:\n            full_results = wrapper.run(f\"{query} (site:*)\")\n            result_list = full_results.split(\"\\n\")[:max_results]\n            limited_results = []\n            for result in result_list:\n                limited_result = {\n                    \"snippet\": result[:max_snippet_length],\n                }\n                limited_results.append(limited_result)\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"duckduckgo_search\",\n            description=\"Search for recent results using DuckDuckGo with result limiting\",\n            func=search_func,\n            args_schema=self.DuckDuckGoSearchSchema,\n        )\n        self.status = \"DuckDuckGo Search Tool created\"\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n        results = tool.run(\n            {\n                \"query\": self.input_value,\n                \"max_results\": self.max_results,\n                \"max_snippet_length\": self.max_snippet_length,\n            }\n        )\n        data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n        self.status = data_list\n        return data_list\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "cryptocurrency",
								"display_name": "Search Query",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"max_results": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_results",
								"value": 5,
								"display_name": "Max Results",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"max_snippet_length": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_snippet_length",
								"value": 100,
								"display_name": "Max Snippet Length",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							}
						},
						"description": "Perform web searches using the DuckDuckGo search engine with result limiting",
						"icon": "DuckDuckGo1",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "DuckDuckGo Search 1",
						"documentation": "https://python.langchain.com/docs/integrations/tools/ddg",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"max_results",
									"max_snippet_length"
								]
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"max_results",
									"max_snippet_length"
								]
							}
						],
						"field_order": [
							"input_value",
							"max_results",
							"max_snippet_length"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "DuckDuckGoSearch-nu1XV"
				},
				"selected": false,
				"width": 384,
				"height": 347,
				"positionAbsolute": {
					"x": 4541.084903257265,
					"y": 1464.2859834348258
				},
				"dragging": false
			},
			{
				"id": "AmazonBedrockModel-I8Ul0",
				"type": "genericNode",
				"position": {
					"x": 1362.5807714093558,
					"y": 881.0160708375353
				},
				"data": {
					"type": "AmazonBedrockModel",
					"node": {
						"template": {
							"_type": "Component",
							"output_parser": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "output_parser",
								"value": "",
								"display_name": "Output Parser",
								"advanced": true,
								"input_types": [
									"OutputParser"
								],
								"dynamic": false,
								"info": "The parser to use to parse the output of the model",
								"title_case": false,
								"type": "other",
								"_input_type": "HandleInput"
							},
							"aws_access_key": {
								"load_from_db": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "aws_access_key",
								"value": "",
								"display_name": "Access Key",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"aws_secret_key": {
								"load_from_db": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "aws_secret_key",
								"value": "",
								"display_name": "Secret Key",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"password": true,
								"type": "str",
								"_input_type": "SecretStrInput"
							},
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from langflow.base.models.model import LCModelComponent\nfrom langflow.field_typing import LanguageModel\nfrom langflow.inputs import MessageTextInput, SecretStrInput\nfrom langflow.inputs.inputs import HandleInput\nfrom langflow.io import DictInput, DropdownInput\n\nclass AmazonBedrockComponent(LCModelComponent):\n    display_name: str = \"Amazon Bedrock\"\n    description: str = \"Generate text using Amazon Bedrock LLMs.\"\n    icon = \"Amazon\"\n    name = \"AmazonBedrockModel\"\n    \n    inputs = LCModelComponent._base_inputs + [\n        DropdownInput(\n            name=\"model_id\",\n            display_name=\"Model ID\",\n            options=[\n                \"amazon.titan-text-express-v1\",\n                \"amazon.titan-text-lite-v1\",\n                \"amazon.titan-text-premier-v1:0\",\n                \"amazon.titan-embed-text-v1\",\n                \"amazon.titan-embed-text-v2:0\",\n                \"amazon.titan-embed-image-v1\",\n                \"amazon.titan-image-generator-v1\",\n                \"anthropic.claude-v2\",\n                \"anthropic.claude-v2:1\",\n                \"anthropic.claude-3-sonnet-20240229-v1:0\",\n                \"anthropic.claude-3-haiku-20240307-v1:0\",\n                \"anthropic.claude-3-opus-20240229-v1:0\",\n                \"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n                \"anthropic.claude-instant-v1\",\n                \"ai21.j2-mid-v1\",\n                \"ai21.j2-ultra-v1\",\n                \"cohere.command-text-v14\",\n                \"cohere.command-light-text-v14\",\n                \"cohere.command-r-v1:0\",\n                \"cohere.command-r-plus-v1:0\",\n                \"cohere.embed-english-v3\",\n                \"cohere.embed-multilingual-v3\",\n                \"meta.llama2-13b-chat-v1\",\n                \"meta.llama2-70b-chat-v1\",\n                \"meta.llama3-8b-instruct-v1:0\",\n                \"meta.llama3-70b-instruct-v1:0\",\n                \"mistral.mistral-7b-instruct-v0:2\",\n                \"mistral.mixtral-8x7b-instruct-v0:1\",\n                \"mistral.mistral-large-2402-v1:0\",\n                \"mistral.mistral-small-2402-v1:0\",\n                \"stability.stable-diffusion-xl-v0\",\n                \"stability.stable-diffusion-xl-v1\",\n            ],\n            value=\"anthropic.claude-3-5-sonnet-20240620-v1:0\",\n        ),\n        SecretStrInput(name=\"aws_access_key\", display_name=\"Access Key\"),\n        SecretStrInput(name=\"aws_secret_key\", display_name=\"Secret Key\"),\n        MessageTextInput(name=\"credentials_profile_name\", display_name=\"Credentials Profile Name\", advanced=True),\n        MessageTextInput(name=\"region_name\", display_name=\"Region Name\", value=\"us-east-1\"),\n        DictInput(name=\"model_kwargs\", display_name=\"Model Kwargs\", advanced=True, is_list=True),\n        MessageTextInput(name=\"endpoint_url\", display_name=\"Endpoint URL\", advanced=True),\n        HandleInput(\n            name=\"output_parser\",\n            display_name=\"Output Parser\",\n            info=\"The parser to use to parse the output of the model\",\n            advanced=True,\n            input_types=[\"OutputParser\"],\n        ),\n    ]\n\n    def build_model(self) -> LanguageModel:  # type: ignore[type-var]\n        try:\n            from langchain_aws import ChatBedrock\n        except ImportError as e:\n            msg = \"langchain_aws is not installed. Please install it with `pip install langchain_aws`.\"\n            raise ImportError(msg) from e\n        if self.aws_access_key:\n            import boto3  # type: ignore\n\n            session = boto3.Session(\n                aws_access_key_id=self.aws_access_key,\n                aws_secret_access_key=self.aws_secret_key,\n            )\n        elif self.credentials_profile_name:\n            import boto3\n\n            session = boto3.Session(profile_name=self.credentials_profile_name)\n        else:\n            import boto3\n\n            session = boto3.Session()\n\n        client_params = {}\n        if self.endpoint_url:\n            client_params[\"endpoint_url\"] = self.endpoint_url\n        if self.region_name:\n            client_params[\"region_name\"] = self.region_name\n\n        boto3_client = session.client(\"bedrock-runtime\", **client_params)\n        try:\n            output = ChatBedrock(  # type: ignore\n                client=boto3_client,\n                model_id=self.model_id,\n                region_name=self.region_name,\n                model_kwargs=self.model_kwargs,\n                endpoint_url=self.endpoint_url,\n                streaming=self.stream,\n            )\n        except Exception as e:\n            msg = \"Could not connect to AmazonBedrock API.\"\n            raise ValueError(msg) from e\n        return output  # type: ignore\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"credentials_profile_name": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "credentials_profile_name",
								"value": "",
								"display_name": "Credentials Profile Name",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"endpoint_url": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "endpoint_url",
								"value": "",
								"display_name": "Endpoint URL",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageInput"
							},
							"model_id": {
								"trace_as_metadata": true,
								"options": [
									"amazon.titan-text-express-v1",
									"amazon.titan-text-lite-v1",
									"amazon.titan-text-premier-v1:0",
									"amazon.titan-embed-text-v1",
									"amazon.titan-embed-text-v2:0",
									"amazon.titan-embed-image-v1",
									"amazon.titan-image-generator-v1",
									"anthropic.claude-v2",
									"anthropic.claude-v2:1",
									"anthropic.claude-3-sonnet-20240229-v1:0",
									"anthropic.claude-3-haiku-20240307-v1:0",
									"anthropic.claude-3-opus-20240229-v1:0",
									"anthropic.claude-3-5-sonnet-20240620-v1:0",
									"anthropic.claude-instant-v1",
									"ai21.j2-mid-v1",
									"ai21.j2-ultra-v1",
									"cohere.command-text-v14",
									"cohere.command-light-text-v14",
									"cohere.command-r-v1:0",
									"cohere.command-r-plus-v1:0",
									"cohere.embed-english-v3",
									"cohere.embed-multilingual-v3",
									"meta.llama2-13b-chat-v1",
									"meta.llama2-70b-chat-v1",
									"meta.llama3-8b-instruct-v1:0",
									"meta.llama3-70b-instruct-v1:0",
									"mistral.mistral-7b-instruct-v0:2",
									"mistral.mixtral-8x7b-instruct-v0:1",
									"mistral.mistral-large-2402-v1:0",
									"mistral.mistral-small-2402-v1:0",
									"stability.stable-diffusion-xl-v0",
									"stability.stable-diffusion-xl-v1"
								],
								"combobox": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "model_id",
								"value": "anthropic.claude-3-5-sonnet-20240620-v1:0",
								"display_name": "Model ID",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "DropdownInput"
							},
							"model_kwargs": {
								"trace_as_input": true,
								"list": true,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "model_kwargs",
								"value": {},
								"display_name": "Model Kwargs",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "dict",
								"_input_type": "DictInput"
							},
							"region_name": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "region_name",
								"value": "us-east-1",
								"display_name": "Region Name",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"stream": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "stream",
								"value": false,
								"display_name": "Stream",
								"advanced": true,
								"dynamic": false,
								"info": "Stream the response from the model. Streaming works only in Chat.",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							},
							"system_message": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "system_message",
								"value": "",
								"display_name": "System Message",
								"advanced": true,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "System message to pass to the model.",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							}
						},
						"description": "Generate text using Amazon Bedrock LLMs.",
						"icon": "Amazon",
						"base_classes": [
							"LanguageModel",
							"Message"
						],
						"display_name": "Amazon Bedrock",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Message"
								],
								"selected": "Message",
								"name": "text_output",
								"display_name": "Text",
								"method": "text_response",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"stream",
									"system_message"
								]
							},
							{
								"types": [
									"LanguageModel"
								],
								"selected": "LanguageModel",
								"name": "model_output",
								"display_name": "Language Model",
								"method": "build_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"aws_access_key",
									"aws_secret_key",
									"credentials_profile_name",
									"endpoint_url",
									"model_id",
									"model_kwargs",
									"region_name",
									"stream"
								]
							}
						],
						"field_order": [
							"input_value",
							"system_message",
							"stream",
							"model_id",
							"aws_access_key",
							"aws_secret_key",
							"credentials_profile_name",
							"region_name",
							"model_kwargs",
							"endpoint_url",
							"output_parser"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "AmazonBedrockModel-I8Ul0"
				},
				"selected": false,
				"width": 384,
				"height": 677,
				"dragging": false,
				"positionAbsolute": {
					"x": 1362.5807714093558,
					"y": 881.0160708375353
				}
			},
			{
				"id": "WikipediaAPI2-MS49r",
				"type": "genericNode",
				"position": {
					"x": 4525.7752473209079,
					"y": 2036.0982548309356
				},
				"data": {
					"type": "WikipediaAPI2",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import cast\n\nfrom langchain_community.tools import WikipediaQueryRun\nfrom langchain_community.utilities.wikipedia import WikipediaAPIWrapper\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import BoolInput, IntInput, MessageTextInput, MultilineInput\nfrom langflow.schema import Data\n\n\nclass WikipediaAPIComponent(LCToolComponent):\n    display_name = \"Wikipedia API\"\n    description = \"Call Wikipedia API.\"\n    name = \"WikipediaAPI2\"\n\n    inputs = [\n        MultilineInput(\n            name=\"input_value\",\n            display_name=\"Input\",\n        ),\n        MessageTextInput(name=\"lang\", display_name=\"Language\", value=\"en\"),\n        IntInput(name=\"k\", display_name=\"Number of results\", value=4, required=True),\n        BoolInput(name=\"load_all_available_meta\", display_name=\"Load all available meta\", value=False, advanced=True),\n        IntInput(\n            name=\"doc_content_chars_max\", display_name=\"Document content characters max\", value=4000, advanced=True\n        ),\n    ]\n\n    def run_model(self) -> list[Data]:\n        wrapper = self._build_wrapper()\n        docs = wrapper.load(self.input_value)\n        data = [Data.from_document(doc) for doc in docs]\n        self.status = data\n        return data\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n        return cast(Tool, WikipediaQueryRun(api_wrapper=wrapper))\n\n    def _build_wrapper(self) -> WikipediaAPIWrapper:\n        return WikipediaAPIWrapper(\n            top_k_results=self.k,\n            lang=self.lang,\n            load_all_available_meta=self.load_all_available_meta,\n            doc_content_chars_max=self.doc_content_chars_max,\n        )\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"doc_content_chars_max": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "doc_content_chars_max",
								"value": 4000,
								"display_name": "Document content characters max",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"input_value": {
								"trace_as_input": true,
								"multiline": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "",
								"display_name": "Input",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MultilineInput"
							},
							"k": {
								"trace_as_metadata": true,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "k",
								"value": 4,
								"display_name": "Number of results",
								"advanced": false,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"lang": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "lang",
								"value": "en",
								"display_name": "Language",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"load_all_available_meta": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "load_all_available_meta",
								"value": false,
								"display_name": "Load all available meta",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "bool",
								"_input_type": "BoolInput"
							}
						},
						"description": "Call Wikipedia API.",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "Wikipedia API 2",
						"documentation": "",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"doc_content_chars_max",
									"input_value",
									"k",
									"lang",
									"load_all_available_meta"
								]
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"doc_content_chars_max",
									"input_value",
									"k",
									"lang",
									"load_all_available_meta"
								]
							}
						],
						"field_order": [
							"input_value",
							"lang",
							"k",
							"load_all_available_meta",
							"doc_content_chars_max"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "WikipediaAPI2-MS49r"
				},
				"selected": false,
				"width": 384,
				"height": 504,
				"positionAbsolute": {
					"x": 4525.7752473209079,
					"y": 2036.0982548309356
				},
				"dragging": false
			},
			{
				"id": "DuckDuckGoSearch-0MnFD",
				"type": "genericNode",
				"position": {
					"x": 4527.667253974564,
					"y": 2588.9550669068964
				},
				"data": {
					"type": "DuckDuckGoSearch",
					"node": {
						"template": {
							"_type": "Component",
							"code": {
								"type": "code",
								"required": true,
								"placeholder": "",
								"list": false,
								"show": true,
								"multiline": true,
								"value": "from typing import Any\n\nfrom langchain.tools import StructuredTool\nfrom langchain_community.tools import DuckDuckGoSearchRun\nfrom pydantic import BaseModel, Field\n\nfrom langflow.base.langchain_utilities.model import LCToolComponent\nfrom langflow.field_typing import Tool\nfrom langflow.inputs import IntInput, MessageTextInput\nfrom langflow.schema import Data\n\n\nclass DuckDuckGoSearchComponent(LCToolComponent):\n    display_name: str = \"DuckDuckGo Search\"\n    description: str = \"Perform web searches using the DuckDuckGo search engine with result limiting\"\n    name = \"DuckDuckGoSearch\"\n    documentation: str = \"https://python.langchain.com/docs/integrations/tools/ddg\"\n    icon: str = \"DuckDuckGo2\"\n    inputs = [\n        MessageTextInput(\n            name=\"input_value\",\n            display_name=\"Search Query\",\n            required=True,\n        ),\n        IntInput(name=\"max_results\", display_name=\"Max Results\", value=5, advanced=True),\n        IntInput(name=\"max_snippet_length\", display_name=\"Max Snippet Length\", value=100, advanced=True),\n    ]\n\n    class DuckDuckGoSearchSchema(BaseModel):\n        query: str = Field(..., description=\"The search query\")\n        max_results: int = Field(5, description=\"Maximum number of results to return\")\n        max_snippet_length: int = Field(100, description=\"Maximum length of each result snippet\")\n\n    def _build_wrapper(self):\n        return DuckDuckGoSearchRun()\n\n    def build_tool(self) -> Tool:\n        wrapper = self._build_wrapper()\n\n        def search_func(query: str, max_results: int = 5, max_snippet_length: int = 100) -> list[dict[str, Any]]:\n            full_results = wrapper.run(f\"{query} (site:*)\")\n            result_list = full_results.split(\"\\n\")[:max_results]\n            limited_results = []\n            for result in result_list:\n                limited_result = {\n                    \"snippet\": result[:max_snippet_length],\n                }\n                limited_results.append(limited_result)\n            return limited_results\n\n        tool = StructuredTool.from_function(\n            name=\"duckduckgo_search\",\n            description=\"Search for recent results using DuckDuckGo with result limiting\",\n            func=search_func,\n            args_schema=self.DuckDuckGoSearchSchema,\n        )\n        self.status = \"DuckDuckGo Search Tool created\"\n        return tool\n\n    def run_model(self) -> list[Data]:\n        tool = self.build_tool()\n        results = tool.run(\n            {\n                \"query\": self.input_value,\n                \"max_results\": self.max_results,\n                \"max_snippet_length\": self.max_snippet_length,\n            }\n        )\n        data_list = [Data(data=result, text=result.get(\"snippet\", \"\")) for result in results]\n        self.status = data_list\n        return data_list\n",
								"fileTypes": [],
								"file_path": "",
								"password": false,
								"name": "code",
								"advanced": true,
								"dynamic": true,
								"info": "",
								"load_from_db": false,
								"title_case": false
							},
							"input_value": {
								"trace_as_input": true,
								"trace_as_metadata": true,
								"load_from_db": false,
								"list": false,
								"required": true,
								"placeholder": "",
								"show": true,
								"name": "input_value",
								"value": "cryptocurrency",
								"display_name": "Search Query",
								"advanced": false,
								"input_types": [
									"Message"
								],
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "str",
								"_input_type": "MessageTextInput"
							},
							"max_results": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_results",
								"value": 5,
								"display_name": "Max Results",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							},
							"max_snippet_length": {
								"trace_as_metadata": true,
								"list": false,
								"required": false,
								"placeholder": "",
								"show": true,
								"name": "max_snippet_length",
								"value": 100,
								"display_name": "Max Snippet Length",
								"advanced": true,
								"dynamic": false,
								"info": "",
								"title_case": false,
								"type": "int",
								"_input_type": "IntInput"
							}
						},
						"description": "Perform web searches using the DuckDuckGo search engine with result limiting",
						"icon": "DuckDuckGo2",
						"base_classes": [
							"Data",
							"Tool"
						],
						"display_name": "DuckDuckGo Search 2",
						"documentation": "https://python.langchain.com/docs/integrations/tools/ddg",
						"custom_fields": {},
						"output_types": [],
						"pinned": false,
						"conditional_paths": [],
						"frozen": false,
						"outputs": [
							{
								"types": [
									"Data"
								],
								"selected": "Data",
								"name": "api_run_model",
								"display_name": "Data",
								"method": "run_model",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"max_results",
									"max_snippet_length"
								]
							},
							{
								"types": [
									"Tool"
								],
								"selected": "Tool",
								"name": "api_build_tool",
								"display_name": "Tool",
								"method": "build_tool",
								"value": "__UNDEFINED__",
								"cache": true,
								"required_inputs": [
									"input_value",
									"max_results",
									"max_snippet_length"
								]
							}
						],
						"field_order": [
							"input_value",
							"max_results",
							"max_snippet_length"
						],
						"beta": false,
						"edited": true,
						"metadata": {},
						"lf_version": "1.0.19"
					},
					"id": "DuckDuckGoSearch-0MnFD"
				},
				"selected": false,
				"width": 384,
				"height": 347,
				"positionAbsolute": {
					"x": 4527.667253974564,
					"y": 2588.9550669068964
				},
				"dragging": false
			}
		],
		"edges": [
			{
				"source": "Prompt-2qjsQ",
				"sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-2qjsQœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "input_value",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Message"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "Prompt",
						"id": "Prompt-2qjsQ",
						"name": "prompt",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-Prompt-2qjsQ{œdataTypeœ:œPromptœ,œidœ:œPrompt-2qjsQœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "ToolCallingAgent-IOK4W",
				"sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-IOK4Wœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
				"target": "ChatOutput-CKza3",
				"targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CKza3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "input_value",
						"id": "ChatOutput-CKza3",
						"inputTypes": [
							"Message"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "ToolCallingAgent",
						"id": "ToolCallingAgent-IOK4W",
						"name": "response",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-ToolCallingAgent-IOK4W{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-IOK4Wœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-ChatOutput-CKza3{œfieldNameœ:œinput_valueœ,œidœ:œChatOutput-CKza3œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "Memory-Qm0Sj",
				"sourceHandle": "{œdataTypeœ:œMemoryœ,œidœ:œMemory-Qm0Sjœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}",
				"target": "Prompt-2qjsQ",
				"targetHandle": "{œfieldNameœ:œconversation_historyœ,œidœ:œPrompt-2qjsQœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "conversation_history",
						"id": "Prompt-2qjsQ",
						"inputTypes": [
							"Message",
							"Text"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "Memory",
						"id": "Memory-Qm0Sj",
						"name": "messages_text",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-Memory-Qm0Sj{œdataTypeœ:œMemoryœ,œidœ:œMemory-Qm0Sjœ,œnameœ:œmessages_textœ,œoutput_typesœ:[œMessageœ]}-Prompt-2qjsQ{œfieldNameœ:œconversation_historyœ,œidœ:œPrompt-2qjsQœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "ChatInput-sHxGF",
				"sourceHandle": "{œdataTypeœ:œChatInputœ,œidœ:œChatInput-sHxGFœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}",
				"target": "Prompt-2qjsQ",
				"targetHandle": "{œfieldNameœ:œinputœ,œidœ:œPrompt-2qjsQœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "input",
						"id": "Prompt-2qjsQ",
						"inputTypes": [
							"Message",
							"Text"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "ChatInput",
						"id": "ChatInput-sHxGF",
						"name": "message",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-ChatInput-sHxGF{œdataTypeœ:œChatInputœ,œidœ:œChatInput-sHxGFœ,œnameœ:œmessageœ,œoutput_typesœ:[œMessageœ]}-Prompt-2qjsQ{œfieldNameœ:œinputœ,œidœ:œPrompt-2qjsQœ,œinputTypesœ:[œMessageœ,œTextœ],œtypeœ:œstrœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "GoogleSerpAPI-4AeX6",
				"sourceHandle": "{œdataTypeœ:œGoogleSerpAPIœ,œidœ:œGoogleSerpAPI-4AeX6œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "GoogleSerpAPI",
						"id": "GoogleSerpAPI-4AeX6",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-GoogleSerpAPI-4AeX6{œdataTypeœ:œGoogleSerpAPIœ,œidœ:œGoogleSerpAPI-4AeX6œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "ToolCallingAgent-IOK4W",
				"sourceHandle": "{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-IOK4Wœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}",
				"target": "TextOutput-WDNg6",
				"targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-WDNg6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "input_value",
						"id": "TextOutput-WDNg6",
						"inputTypes": [
							"Message"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "ToolCallingAgent",
						"id": "ToolCallingAgent-IOK4W",
						"name": "response",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-ToolCallingAgent-IOK4W{œdataTypeœ:œToolCallingAgentœ,œidœ:œToolCallingAgent-IOK4Wœ,œnameœ:œresponseœ,œoutput_typesœ:[œMessageœ]}-TextOutput-WDNg6{œfieldNameœ:œinput_valueœ,œidœ:œTextOutput-WDNg6œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "WikipediaAPI-ioGxI",
				"sourceHandle": "{œdataTypeœ:œWikipediaAPIœ,œidœ:œWikipediaAPI-ioGxIœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "WikipediaAPI",
						"id": "WikipediaAPI-ioGxI",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-WikipediaAPI-ioGxI{œdataTypeœ:œWikipediaAPIœ,œidœ:œWikipediaAPI-ioGxIœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "DuckDuckGoSearch-GlscT",
				"sourceHandle": "{œdataTypeœ:œDuckDuckGoSearchœ,œidœ:œDuckDuckGoSearch-GlscTœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "DuckDuckGoSearch",
						"id": "DuckDuckGoSearch-GlscT",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-DuckDuckGoSearch-GlscT{œdataTypeœ:œDuckDuckGoSearchœ,œidœ:œDuckDuckGoSearch-GlscTœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "NewsAPI-fcZCA",
				"sourceHandle": "{œdataTypeœ:œNewsAPIœ,œidœ:œNewsAPI-fcZCAœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "NewsAPI",
						"id": "NewsAPI-fcZCA",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-NewsAPI-fcZCA{œdataTypeœ:œNewsAPIœ,œidœ:œNewsAPI-fcZCAœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "CoinMarketCapAPI-TIwe5",
				"sourceHandle": "{œdataTypeœ:œCoinMarketCapAPIœ,œidœ:œCoinMarketCapAPI-TIwe5œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "CoinMarketCapAPI",
						"id": "CoinMarketCapAPI-TIwe5",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-CoinMarketCapAPI-TIwe5{œdataTypeœ:œCoinMarketCapAPIœ,œidœ:œCoinMarketCapAPI-TIwe5œ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "YahooFinanceCrypto-aYcOX",
				"sourceHandle": "{œdataTypeœ:œYahooFinanceCryptoœ,œidœ:œYahooFinanceCrypto-aYcOXœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "YahooFinanceCrypto",
						"id": "YahooFinanceCrypto-aYcOX",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-YahooFinanceCrypto-aYcOX{œdataTypeœ:œYahooFinanceCryptoœ,œidœ:œYahooFinanceCrypto-aYcOXœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "CoinGeckoAPI-UxBhk",
				"sourceHandle": "{œdataTypeœ:œCoinGeckoAPIœ,œidœ:œCoinGeckoAPI-UxBhkœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "CoinGeckoAPI",
						"id": "CoinGeckoAPI-UxBhk",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-CoinGeckoAPI-UxBhk{œdataTypeœ:œCoinGeckoAPIœ,œidœ:œCoinGeckoAPI-UxBhkœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "OpenAIModel-MEUqM",
				"sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-MEUqMœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
				"target": "ToolCallingAgent-c5w9e",
				"targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "llm",
						"id": "ToolCallingAgent-c5w9e",
						"inputTypes": [
							"LanguageModel"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "OpenAIModel",
						"id": "OpenAIModel-MEUqM",
						"name": "model_output",
						"output_types": [
							"LanguageModel"
						]
					}
				},
				"id": "reactflow__edge-OpenAIModel-MEUqM{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-MEUqMœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-c5w9e{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
				"className": "",
				"animated": false
			},
			{
				"source": "Prompt-ldALf",
				"sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-ldALfœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
				"target": "ToolCallingAgent-c5w9e",
				"targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "input_value",
						"id": "ToolCallingAgent-c5w9e",
						"inputTypes": [
							"Message"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "Prompt",
						"id": "Prompt-ldALf",
						"name": "prompt",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-Prompt-ldALf{œdataTypeœ:œPromptœ,œidœ:œPrompt-ldALfœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-c5w9e{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"className": "",
				"animated": false
			},
			{
				"source": "OpenAIModel-EaIce",
				"sourceHandle": "{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-EaIceœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
				"target": "ToolCallingAgent-b1Kk9",
				"targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "llm",
						"id": "ToolCallingAgent-b1Kk9",
						"inputTypes": [
							"LanguageModel"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "OpenAIModel",
						"id": "OpenAIModel-EaIce",
						"name": "model_output",
						"output_types": [
							"LanguageModel"
						]
					}
				},
				"id": "reactflow__edge-OpenAIModel-EaIce{œdataTypeœ:œOpenAIModelœ,œidœ:œOpenAIModel-EaIceœ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-b1Kk9{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
				"className": "",
				"animated": false
			},
			{
				"source": "Prompt-fqS6s",
				"sourceHandle": "{œdataTypeœ:œPromptœ,œidœ:œPrompt-fqS6sœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}",
				"target": "ToolCallingAgent-b1Kk9",
				"targetHandle": "{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"data": {
					"targetHandle": {
						"fieldName": "input_value",
						"id": "ToolCallingAgent-b1Kk9",
						"inputTypes": [
							"Message"
						],
						"type": "str"
					},
					"sourceHandle": {
						"dataType": "Prompt",
						"id": "Prompt-fqS6s",
						"name": "prompt",
						"output_types": [
							"Message"
						]
					}
				},
				"id": "reactflow__edge-Prompt-fqS6s{œdataTypeœ:œPromptœ,œidœ:œPrompt-fqS6sœ,œnameœ:œpromptœ,œoutput_typesœ:[œMessageœ]}-ToolCallingAgent-b1Kk9{œfieldNameœ:œinput_valueœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œMessageœ],œtypeœ:œstrœ}",
				"className": "",
				"animated": false
			},
			{
				"source": "YahooFinanceTool-DYxhl",
				"sourceHandle": "{œdataTypeœ:œYahooFinanceToolœ,œidœ:œYahooFinanceTool-DYxhlœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "YahooFinanceTool",
						"id": "YahooFinanceTool-DYxhl",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-YahooFinanceTool-DYxhl{œdataTypeœ:œYahooFinanceToolœ,œidœ:œYahooFinanceTool-DYxhlœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"className": "",
				"animated": false
			},
			{
				"source": "DuckDuckGoSearch-nu1XV",
				"sourceHandle": "{œdataTypeœ:œDuckDuckGoSearchœ,œidœ:œDuckDuckGoSearch-nu1XVœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-c5w9e",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-c5w9e",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "DuckDuckGoSearch",
						"id": "DuckDuckGoSearch-nu1XV",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-DuckDuckGoSearch-nu1XV{œdataTypeœ:œDuckDuckGoSearchœ,œidœ:œDuckDuckGoSearch-nu1XVœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-c5w9e{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "AmazonBedrockModel-I8Ul0",
				"sourceHandle": "{œdataTypeœ:œAmazonBedrockModelœ,œidœ:œAmazonBedrockModel-I8Ul0œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "llm",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"LanguageModel"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "AmazonBedrockModel",
						"id": "AmazonBedrockModel-I8Ul0",
						"name": "model_output",
						"output_types": [
							"LanguageModel"
						]
					}
				},
				"id": "reactflow__edge-AmazonBedrockModel-I8Ul0{œdataTypeœ:œAmazonBedrockModelœ,œidœ:œAmazonBedrockModel-I8Ul0œ,œnameœ:œmodel_outputœ,œoutput_typesœ:[œLanguageModelœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œllmœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œLanguageModelœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "DuckDuckGoSearch-0MnFD",
				"sourceHandle": "{œdataTypeœ:œDuckDuckGoSearchœ,œidœ:œDuckDuckGoSearch-0MnFDœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-b1Kk9",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-b1Kk9",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "DuckDuckGoSearch",
						"id": "DuckDuckGoSearch-0MnFD",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-DuckDuckGoSearch-0MnFD{œdataTypeœ:œDuckDuckGoSearchœ,œidœ:œDuckDuckGoSearch-0MnFDœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-b1Kk9{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "WikipediaAPI2-MS49r",
				"sourceHandle": "{œdataTypeœ:œWikipediaAPI2œ,œidœ:œWikipediaAPI2-MS49rœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-b1Kk9",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-b1Kk9",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "WikipediaAPI2",
						"id": "WikipediaAPI2-MS49r",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-WikipediaAPI2-MS49r{œdataTypeœ:œWikipediaAPI2œ,œidœ:œWikipediaAPI2-MS49rœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-b1Kk9{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-b1Kk9œ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "WikipediaAPI1-SGBxx",
				"sourceHandle": "{œdataTypeœ:œWikipediaAPI1œ,œidœ:œWikipediaAPI1-SGBxxœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-c5w9e",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-c5w9e",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "WikipediaAPI1",
						"id": "WikipediaAPI1-SGBxx",
						"name": "api_build_tool",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-WikipediaAPI1-SGBxx{œdataTypeœ:œWikipediaAPI1œ,œidœ:œWikipediaAPI1-SGBxxœ,œnameœ:œapi_build_toolœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-c5w9e{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-c5w9eœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "ToolCallingAgent-c5w9e",
				"sourceHandle": "{œdataTypeœ:œToolCallingAgent_Classificationœ,œidœ:œToolCallingAgent-c5w9eœ,œnameœ:œagentœ,œoutput_typesœ:[œAgentExecutorœ]}",
				"target": "AgentAsTool-qe9Bj",
				"targetHandle": "{œfieldNameœ:œagentœ,œidœ:œAgentAsTool-qe9Bjœ,œinputTypesœ:[œAgentExecutorœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "agent",
						"id": "AgentAsTool-qe9Bj",
						"inputTypes": [
							"AgentExecutor"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "ToolCallingAgent_Classification",
						"id": "ToolCallingAgent-c5w9e",
						"name": "agent",
						"output_types": [
							"AgentExecutor"
						]
					}
				},
				"id": "reactflow__edge-ToolCallingAgent-c5w9e{œdataTypeœ:œToolCallingAgent_Classificationœ,œidœ:œToolCallingAgent-c5w9eœ,œnameœ:œagentœ,œoutput_typesœ:[œAgentExecutorœ]}-AgentAsTool-qe9Bj{œfieldNameœ:œagentœ,œidœ:œAgentAsTool-qe9Bjœ,œinputTypesœ:[œAgentExecutorœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "ToolCallingAgent-b1Kk9",
				"sourceHandle": "{œdataTypeœ:œToolCallingAgent_Sentimentœ,œidœ:œToolCallingAgent-b1Kk9œ,œnameœ:œagentœ,œoutput_typesœ:[œAgentExecutorœ]}",
				"target": "AgentAsTool-q4NJV",
				"targetHandle": "{œfieldNameœ:œagentœ,œidœ:œAgentAsTool-q4NJVœ,œinputTypesœ:[œAgentExecutorœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "agent",
						"id": "AgentAsTool-q4NJV",
						"inputTypes": [
							"AgentExecutor"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "ToolCallingAgent_Sentiment",
						"id": "ToolCallingAgent-b1Kk9",
						"name": "agent",
						"output_types": [
							"AgentExecutor"
						]
					}
				},
				"id": "reactflow__edge-ToolCallingAgent-b1Kk9{œdataTypeœ:œToolCallingAgent_Sentimentœ,œidœ:œToolCallingAgent-b1Kk9œ,œnameœ:œagentœ,œoutput_typesœ:[œAgentExecutorœ]}-AgentAsTool-q4NJV{œfieldNameœ:œagentœ,œidœ:œAgentAsTool-q4NJVœ,œinputTypesœ:[œAgentExecutorœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "AgentAsTool-qe9Bj",
				"sourceHandle": "{œdataTypeœ:œAgentAsTool_Classificationœ,œidœ:œAgentAsTool-qe9Bjœ,œnameœ:œagent_tool_classificationœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "AgentAsTool_Classification",
						"id": "AgentAsTool-qe9Bj",
						"name": "agent_tool_classification",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-AgentAsTool-qe9Bj{œdataTypeœ:œAgentAsTool_Classificationœ,œidœ:œAgentAsTool-qe9Bjœ,œnameœ:œagent_tool_classificationœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			},
			{
				"source": "AgentAsTool-q4NJV",
				"sourceHandle": "{œdataTypeœ:œAgentAsTool_Sentimentœ,œidœ:œAgentAsTool-q4NJVœ,œnameœ:œagent_tool_sentimentœ,œoutput_typesœ:[œToolœ]}",
				"target": "ToolCallingAgent-IOK4W",
				"targetHandle": "{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"data": {
					"targetHandle": {
						"fieldName": "tools",
						"id": "ToolCallingAgent-IOK4W",
						"inputTypes": [
							"Tool",
							"BaseTool",
							"StructuredTool"
						],
						"type": "other"
					},
					"sourceHandle": {
						"dataType": "AgentAsTool_Sentiment",
						"id": "AgentAsTool-q4NJV",
						"name": "agent_tool_sentiment",
						"output_types": [
							"Tool"
						]
					}
				},
				"id": "reactflow__edge-AgentAsTool-q4NJV{œdataTypeœ:œAgentAsTool_Sentimentœ,œidœ:œAgentAsTool-q4NJVœ,œnameœ:œagent_tool_sentimentœ,œoutput_typesœ:[œToolœ]}-ToolCallingAgent-IOK4W{œfieldNameœ:œtoolsœ,œidœ:œToolCallingAgent-IOK4Wœ,œinputTypesœ:[œToolœ,œBaseToolœ,œStructuredToolœ],œtypeœ:œotherœ}",
				"animated": false,
				"className": ""
			}
		],
		"viewport": {
			"x": -444.032360098372,
			"y": 197.54496602818109,
			"zoom": 0.5449762341459431
		}
	},
	"description": "Engineered for Excellence, Built for Business.",
	"name": "smart_agent_with_tools_and_classification_agent (1)",
	"last_tested_version": "1.0.19",
	"endpoint_name": null,
	"is_component": false
}